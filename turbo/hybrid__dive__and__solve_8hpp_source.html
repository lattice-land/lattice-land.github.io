<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.12.0"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Turbo Constraint Solver: include/hybrid_dive_and_solve.hpp Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/javascript" src="clipboard.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="cookie.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  extensions: ["tex2jax.js"],
  jax: ["input/TeX","output/HTML-CSS"],
});
</script>
<script type="text/javascript" async="async" src="https://cdn.jsdelivr.net/npm/mathjax@2/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Turbo Constraint Solver
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.12.0 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() { codefold.init(0); });
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search',true);
  $(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function(){initNavTree('hybrid__dive__and__solve_8hpp_source.html',''); initResizable(true); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div class="header">
  <div class="headertitle"><div class="title">hybrid_dive_and_solve.hpp</div></div>
</div><!--header-->
<div class="contents">
<a href="hybrid__dive__and__solve_8hpp.html">Go to the documentation of this file.</a><div class="fragment"><div class="line"><a id="l00001" name="l00001"></a><span class="lineno">    1</span><span class="comment">// Copyright 2024 Pierre Talbot</span></div>
<div class="line"><a id="l00002" name="l00002"></a><span class="lineno">    2</span> </div>
<div class="line"><a id="l00003" name="l00003"></a><span class="lineno">    3</span><span class="preprocessor">#ifndef TURBO_HYBRID_DIVE_AND_SOLVE_HPP</span></div>
<div class="line"><a id="l00004" name="l00004"></a><span class="lineno">    4</span><span class="preprocessor">#define TURBO_HYBRID_DIVE_AND_SOLVE_HPP</span></div>
<div class="line"><a id="l00005" name="l00005"></a><span class="lineno">    5</span> </div>
<div class="line"><a id="l00006" name="l00006"></a><span class="lineno">    6</span><span class="preprocessor">#include &quot;<a class="code" href="common__solving_8hpp.html">common_solving.hpp</a>&quot;</span></div>
<div class="line"><a id="l00007" name="l00007"></a><span class="lineno">    7</span><span class="preprocessor">#include &lt;mutex&gt;</span></div>
<div class="line"><a id="l00008" name="l00008"></a><span class="lineno">    8</span><span class="preprocessor">#include &lt;thread&gt;</span></div>
<div class="line"><a id="l00009" name="l00009"></a><span class="lineno">    9</span> </div>
<div class="line"><a id="l00010" name="l00010"></a><span class="lineno">   10</span><span class="keyword">namespace </span>bt = ::battery;</div>
<div class="line"><a id="l00011" name="l00011"></a><span class="lineno">   11</span><span class="comment"></span> </div>
<div class="line"><a id="l00012" name="l00012"></a><span class="lineno">   12</span><span class="comment">/**</span></div>
<div class="line"><a id="l00013" name="l00013"></a><span class="lineno">   13</span><span class="comment"> * &quot;Dive and solve&quot; is a new algorithm to parallelize the standard &quot;propagate and search&quot; algorithm of constraint programming.</span></div>
<div class="line"><a id="l00014" name="l00014"></a><span class="lineno">   14</span><span class="comment"> * Given a depth `d`, we create `2^d` subproblems that we solve in parallel.</span></div>
<div class="line"><a id="l00015" name="l00015"></a><span class="lineno">   15</span><span class="comment"> * We create as many CPU threads as blocks on the GPU (option `config.or_nodes`).</span></div>
<div class="line"><a id="l00016" name="l00016"></a><span class="lineno">   16</span><span class="comment"> * A CPU thread takes the next subproblem available and run the &quot;propagate and search&quot; algorithm on it.</span></div>
<div class="line"><a id="l00017" name="l00017"></a><span class="lineno">   17</span><span class="comment"> * The CPU thread offloads the propagation to the GPU, but take care of splitting and backtracking in the search tree, as well as maintaining the best bound found, and the statistics.</span></div>
<div class="line"><a id="l00018" name="l00018"></a><span class="lineno">   18</span><span class="comment"> * Therefore, a kernel with only 1 block is executed each time we propagate a node.</span></div>
<div class="line"><a id="l00019" name="l00019"></a><span class="lineno">   19</span><span class="comment"> * Since many CPU threads execute in parallel, there are many kernels running in parallel.</span></div>
<div class="line"><a id="l00020" name="l00020"></a><span class="lineno">   20</span><span class="comment"> *</span></div>
<div class="line"><a id="l00021" name="l00021"></a><span class="lineno">   21</span><span class="comment"> * We call a task solving a subproblem a &quot;cube&quot; (this loosely follows the terminology of SAT solving with &quot;cube and conquer&quot;).</span></div>
<div class="line"><a id="l00022" name="l00022"></a><span class="lineno">   22</span><span class="comment"> * By CPU cube, we refer to the local state of a CPU thread for solving a subproblem.</span></div>
<div class="line"><a id="l00023" name="l00023"></a><span class="lineno">   23</span><span class="comment"> * By GPU cube, we refer to the local state of a GPU block for solving a subproblem.</span></div>
<div class="line"><a id="l00024" name="l00024"></a><span class="lineno">   24</span><span class="comment"> * Note that at each moment, there are at most `config.or_nodes` cubes active in parallel.</span></div>
<div class="line"><a id="l00025" name="l00025"></a><span class="lineno">   25</span><span class="comment"> */</span></div>
<div class="line"><a id="l00026" name="l00026"></a><span class="lineno">   26</span> </div>
<div class="line"><a id="l00027" name="l00027"></a><span class="lineno">   27</span><span class="preprocessor">#ifdef __CUDACC__</span></div>
<div class="line"><a id="l00028" name="l00028"></a><span class="lineno">   28</span><span class="comment"></span> </div>
<div class="line"><a id="l00029" name="l00029"></a><span class="lineno">   29</span><span class="comment">/** We only need a few bytes for the shared memory. */</span></div>
<div class="line"><a id="l00030" name="l00030"></a><span class="lineno">   30</span><span class="preprocessor">#define DEFAULT_SHARED_MEM_BYTES 100</span></div>
<div class="line"><a id="l00031" name="l00031"></a><span class="lineno">   31</span><span class="comment"></span> </div>
<div class="line"><a id="l00032" name="l00032"></a><span class="lineno">   32</span><span class="comment">/** A CPU cube is the data used by a CPU thread to solve a subproblem. */</span></div>
<div class="line"><a id="l00033" name="l00033"></a><span class="lineno">   33</span><span class="keyword">struct </span>CPUCube {</div>
<div class="line"><a id="l00034" name="l00034"></a><span class="lineno">   34</span>  <span class="keyword">using </span>cube_type = <a class="code hl_struct" href="struct_abstract_domains.html">AbstractDomains</a>&lt;</div>
<div class="line"><a id="l00035" name="l00035"></a><span class="lineno">   35</span>    <a class="code hl_typedef" href="common__solving_8hpp.html#ab7cbd01c4c671c527f582fffb1125923">Itv</a>, bt::standard_allocator, <a class="code hl_struct" href="struct_unique_light_alloc.html">UniqueLightAlloc&lt;bt::standard_allocator,0&gt;</a>, bt::managed_allocator&gt;;<span class="comment"></span></div>
<div class="line"><a id="l00036" name="l00036"></a><span class="lineno">   36</span><span class="comment">  /** A CPU cube is fully allocated on the CPU, but for the store of variables `cube.store` which is allocated in managed memory.</span></div>
<div class="line"><a id="l00037" name="l00037"></a><span class="lineno">   37</span><span class="comment">   * Indeed, when exchanging information between a GPU cube and a CPU cube, only the store of variables need to be transfered.</span></div>
<div class="line"><a id="l00038" name="l00038"></a><span class="lineno">   38</span><span class="comment">   */</span></div>
<div class="line"><a id="l00039" name="l00039"></a><span class="lineno">   39</span>  cube_type cube;</div>
<div class="line"><a id="l00040" name="l00040"></a><span class="lineno">   40</span><span class="comment"></span> </div>
<div class="line"><a id="l00041" name="l00041"></a><span class="lineno">   41</span><span class="comment">  /** We keep a snapshot of the root to reinitialize the CPU cube after each subproblem has been solved. */</span></div>
<div class="line"><a id="l00042" name="l00042"></a><span class="lineno">   42</span>  <span class="keyword">typename</span> cube_type::IST::snapshot_type&lt;bt::standard_allocator&gt; root_snapshot;</div>
<div class="line"><a id="l00043" name="l00043"></a><span class="lineno">   43</span><span class="comment"></span> </div>
<div class="line"><a id="l00044" name="l00044"></a><span class="lineno">   44</span><span class="comment">  /** This flag becomes `true` when the thread has finished its execution (it exits `dive_and_solve` function). */</span></div>
<div class="line"><a id="l00045" name="l00045"></a><span class="lineno">   45</span>  std::atomic_flag finished;</div>
<div class="line"><a id="l00046" name="l00046"></a><span class="lineno">   46</span><span class="comment"></span> </div>
<div class="line"><a id="l00047" name="l00047"></a><span class="lineno">   47</span><span class="comment">  /** This is the path to the subproblem needed to be solved by this cube.</span></div>
<div class="line"><a id="l00048" name="l00048"></a><span class="lineno">   48</span><span class="comment">   * This member is initialized in `CPUData` constructor.</span></div>
<div class="line"><a id="l00049" name="l00049"></a><span class="lineno">   49</span><span class="comment">   */</span></div>
<div class="line"><a id="l00050" name="l00050"></a><span class="lineno">   50</span>  <span class="keywordtype">size_t</span> subproblem_idx;</div>
<div class="line"><a id="l00051" name="l00051"></a><span class="lineno">   51</span> </div>
<div class="line"><a id="l00052" name="l00052"></a><span class="lineno">   52</span>  CPUCube(<span class="keyword">const</span> <a class="code hl_struct" href="struct_abstract_domains.html">CP&lt;Itv&gt;</a>&amp; root)</div>
<div class="line"><a id="l00053" name="l00053"></a><span class="lineno">   53</span>   : cube(root)</div>
<div class="line"><a id="l00054" name="l00054"></a><span class="lineno">   54</span>   , root_snapshot(cube.search_tree-&gt;template snapshot&lt;bt::standard_allocator&gt;())</div>
<div class="line"><a id="l00055" name="l00055"></a><span class="lineno">   55</span>  {}</div>
<div class="line"><a id="l00056" name="l00056"></a><span class="lineno">   56</span>};</div>
<div class="line"><a id="l00057" name="l00057"></a><span class="lineno">   57</span><span class="comment"></span> </div>
<div class="line"><a id="l00058" name="l00058"></a><span class="lineno">   58</span><span class="comment">/** A GPU cube is the data used by a GPU block to solve a subproblem.</span></div>
<div class="line"><a id="l00059" name="l00059"></a><span class="lineno">   59</span><span class="comment"> * We only allocate the necessary structures to perform propagation: the store of variables and the propagators.</span></div>
<div class="line"><a id="l00060" name="l00060"></a><span class="lineno">   60</span><span class="comment">*/</span></div>
<div class="line"><a id="l00061" name="l00061"></a><span class="lineno">   61</span><span class="keyword">struct </span>GPUCube {<span class="comment"></span></div>
<div class="line"><a id="l00062" name="l00062"></a><span class="lineno">   62</span><span class="comment">  /** We use atomic to store the interval&#39;s lower and upper bounds. */</span></div>
<div class="line"><a id="l00063" name="l00063"></a><span class="lineno">   63</span>  <span class="keyword">using </span>Itv1 = Interval&lt;ZLB&lt;int, bt::atomic_memory_block&gt;&gt;;</div>
<div class="line"><a id="l00064" name="l00064"></a><span class="lineno">   64</span><span class="comment"></span> </div>
<div class="line"><a id="l00065" name="l00065"></a><span class="lineno">   65</span><span class="comment">  /** We use a `pool_allocator`, this allows to easily switch between global memory and shared memory, if the store of variables can fit inside. */</span></div>
<div class="line"><a id="l00066" name="l00066"></a><span class="lineno">   66</span>  <span class="keyword">using </span>IStore = VStore&lt;Itv1, bt::pool_allocator&gt;;</div>
<div class="line"><a id="l00067" name="l00067"></a><span class="lineno">   67</span><span class="comment"></span> </div>
<div class="line"><a id="l00068" name="l00068"></a><span class="lineno">   68</span><span class="comment">  /** The store of propagators also uses a `pool_allocator` of global memory. This was necessary due to the slow copy of propagators between CPU and GPU.</span></div>
<div class="line"><a id="l00069" name="l00069"></a><span class="lineno">   69</span><span class="comment">   * Indeed, a propagator is a tree-shaped object (like an AST) that contain many pointers, and thus the copy calls the allocation function a lot. */</span></div>
<div class="line"><a id="l00070" name="l00070"></a><span class="lineno">   70</span>  <span class="keyword">using </span>IPC = PC&lt;IStore, bt::pool_allocator&gt;;</div>
<div class="line"><a id="l00071" name="l00071"></a><span class="lineno">   71</span><span class="comment"></span> </div>
<div class="line"><a id="l00072" name="l00072"></a><span class="lineno">   72</span><span class="comment">  /** The store of variables is only accessible on GPU. */</span></div>
<div class="line"><a id="l00073" name="l00073"></a><span class="lineno">   73</span>  abstract_ptr&lt;IStore&gt; store_gpu;</div>
<div class="line"><a id="l00074" name="l00074"></a><span class="lineno">   74</span><span class="comment"></span> </div>
<div class="line"><a id="l00075" name="l00075"></a><span class="lineno">   75</span><span class="comment">  /** The propagators is only accessible on GPU but the array of propagators is shared among all blocks.</span></div>
<div class="line"><a id="l00076" name="l00076"></a><span class="lineno">   76</span><span class="comment">   * Since the propagators are state-less, we avoid duplicating them in each block.</span></div>
<div class="line"><a id="l00077" name="l00077"></a><span class="lineno">   77</span><span class="comment">   */</span></div>
<div class="line"><a id="l00078" name="l00078"></a><span class="lineno">   78</span>  abstract_ptr&lt;IPC&gt; ipc_gpu;</div>
<div class="line"><a id="l00079" name="l00079"></a><span class="lineno">   79</span><span class="comment"></span> </div>
<div class="line"><a id="l00080" name="l00080"></a><span class="lineno">   80</span><span class="comment">  /** We also have a store of variables in managed memory to communicate the results of the propagation to the CPU.</span></div>
<div class="line"><a id="l00081" name="l00081"></a><span class="lineno">   81</span><span class="comment">   * Note that this store is the same than the one in the corresponding CPU cube (`cube.store`).</span></div>
<div class="line"><a id="l00082" name="l00082"></a><span class="lineno">   82</span><span class="comment">   * This member is initialized in `CPUData` constructor.</span></div>
<div class="line"><a id="l00083" name="l00083"></a><span class="lineno">   83</span><span class="comment">   */</span></div>
<div class="line"><a id="l00084" name="l00084"></a><span class="lineno">   84</span>  abstract_ptr&lt;VStore&lt;Itv, bt::managed_allocator&gt;&gt; store_cpu;</div>
<div class="line"><a id="l00085" name="l00085"></a><span class="lineno">   85</span><span class="comment"></span> </div>
<div class="line"><a id="l00086" name="l00086"></a><span class="lineno">   86</span><span class="comment">  /** The cumulative number of iterations required to reach a fixpoint.</span></div>
<div class="line"><a id="l00087" name="l00087"></a><span class="lineno">   87</span><span class="comment">   * By dividing this statistic by the number of nodes, we get the average number of iterations per node.</span></div>
<div class="line"><a id="l00088" name="l00088"></a><span class="lineno">   88</span><span class="comment">   */</span></div>
<div class="line"><a id="l00089" name="l00089"></a><span class="lineno">   89</span>  <span class="keywordtype">size_t</span> fp_iterations;</div>
<div class="line"><a id="l00090" name="l00090"></a><span class="lineno">   90</span><span class="comment"></span> </div>
<div class="line"><a id="l00091" name="l00091"></a><span class="lineno">   91</span><span class="comment">  /** The CPU thread and the GPU block use those two flags to signal to each other when to work and when to wait.</span></div>
<div class="line"><a id="l00092" name="l00092"></a><span class="lineno">   92</span><span class="comment">   * This is necessary due to the persistent kernel design of this algorithm.</span></div>
<div class="line"><a id="l00093" name="l00093"></a><span class="lineno">   93</span><span class="comment">   */</span></div>
<div class="line"><a id="l00094" name="l00094"></a><span class="lineno">   94</span>  cuda::std::atomic_flag ready_to_propagate;</div>
<div class="line"><a id="l00095" name="l00095"></a><span class="lineno">   95</span>  cuda::std::atomic_flag ready_to_search;</div>
<div class="line"><a id="l00096" name="l00096"></a><span class="lineno">   96</span><span class="comment"></span> </div>
<div class="line"><a id="l00097" name="l00097"></a><span class="lineno">   97</span><span class="comment">  /** A flag to notify the kernel it must stop. */</span></div>
<div class="line"><a id="l00098" name="l00098"></a><span class="lineno">   98</span>  cuda::std::atomic_flag stop;</div>
<div class="line"><a id="l00099" name="l00099"></a><span class="lineno">   99</span> </div>
<div class="line"><a id="l00100" name="l00100"></a><span class="lineno">  100</span>  GPUCube() {<span class="comment"></span></div>
<div class="line"><a id="l00101" name="l00101"></a><span class="lineno">  101</span><span class="comment">    /** Initially, we are not ready to propagate or to search. */</span></div>
<div class="line"><a id="l00102" name="l00102"></a><span class="lineno">  102</span>    ready_to_search.clear();</div>
<div class="line"><a id="l00103" name="l00103"></a><span class="lineno">  103</span>    ready_to_propagate.clear();</div>
<div class="line"><a id="l00104" name="l00104"></a><span class="lineno">  104</span>    stop.clear();</div>
<div class="line"><a id="l00105" name="l00105"></a><span class="lineno">  105</span>    cuda::atomic_thread_fence(cuda::memory_order_seq_cst, cuda::thread_scope_system);</div>
<div class="line"><a id="l00106" name="l00106"></a><span class="lineno">  106</span>  }</div>
<div class="line"><a id="l00107" name="l00107"></a><span class="lineno">  107</span><span class="comment"></span> </div>
<div class="line"><a id="l00108" name="l00108"></a><span class="lineno">  108</span><span class="comment">  /** Initialize the store of variables and propagators from existing store and propagators.</span></div>
<div class="line"><a id="l00109" name="l00109"></a><span class="lineno">  109</span><span class="comment">   * If `pc_shared` is `true`, the propagators if this cube will be shared with `pc`.</span></div>
<div class="line"><a id="l00110" name="l00110"></a><span class="lineno">  110</span><span class="comment">   * Otherwise, a full copy of the propagators is made.</span></div>
<div class="line"><a id="l00111" name="l00111"></a><span class="lineno">  111</span><span class="comment">   * We generally want to share the propagators, hence the cube 0 copies the propagators, and all other cubes share them.</span></div>
<div class="line"><a id="l00112" name="l00112"></a><span class="lineno">  112</span><span class="comment">  */</span></div>
<div class="line"><a id="l00113" name="l00113"></a><span class="lineno">  113</span>  <span class="keyword">template</span> &lt;<span class="keyword">class</span> StoreType, <span class="keyword">class</span> PCType&gt;</div>
<div class="line"><a id="l00114" name="l00114"></a><span class="lineno">  114</span>  __device__ <span class="keywordtype">void</span> allocate(StoreType&amp; store, PCType&amp; pc, <span class="keywordtype">size_t</span> bytes, <span class="keywordtype">bool</span> pc_shared) {</div>
<div class="line"><a id="l00115" name="l00115"></a><span class="lineno">  115</span>    <span class="keywordtype">void</span>* mem_pool = bt::global_allocator{}.allocate(bytes);</div>
<div class="line"><a id="l00116" name="l00116"></a><span class="lineno">  116</span>    bt::pool_allocator pool(<span class="keyword">static_cast&lt;</span><span class="keywordtype">unsigned</span> <span class="keywordtype">char</span>*<span class="keyword">&gt;</span>(mem_pool), bytes);</div>
<div class="line"><a id="l00117" name="l00117"></a><span class="lineno">  117</span>    AbstractDeps&lt;bt::global_allocator, bt::pool_allocator&gt; deps(pc_shared, bt::global_allocator{}, pool);</div>
<div class="line"><a id="l00118" name="l00118"></a><span class="lineno">  118</span>    ipc_gpu = bt::allocate_shared&lt;IPC, bt::pool_allocator&gt;(pool, pc, deps);</div>
<div class="line"><a id="l00119" name="l00119"></a><span class="lineno">  119</span>    store_gpu = deps.template extract&lt;IStore&gt;(store.aty());</div>
<div class="line"><a id="l00120" name="l00120"></a><span class="lineno">  120</span>  }</div>
<div class="line"><a id="l00121" name="l00121"></a><span class="lineno">  121</span> </div>
<div class="line"><a id="l00122" name="l00122"></a><span class="lineno">  122</span>  __device__ <span class="keywordtype">void</span> deallocate() {</div>
<div class="line"><a id="l00123" name="l00123"></a><span class="lineno">  123</span>    <span class="comment">// NOTE: .reset() does not work because it does not reset the allocator, which is itself allocated in global memory.</span></div>
<div class="line"><a id="l00124" name="l00124"></a><span class="lineno">  124</span>    store_gpu = abstract_ptr&lt;IStore&gt;();</div>
<div class="line"><a id="l00125" name="l00125"></a><span class="lineno">  125</span>    ipc_gpu = abstract_ptr&lt;IPC&gt;();</div>
<div class="line"><a id="l00126" name="l00126"></a><span class="lineno">  126</span>  }</div>
<div class="line"><a id="l00127" name="l00127"></a><span class="lineno">  127</span>};</div>
<div class="line"><a id="l00128" name="l00128"></a><span class="lineno">  128</span><span class="comment"></span> </div>
<div class="line"><a id="l00129" name="l00129"></a><span class="lineno">  129</span><span class="comment">/** This kernel initializes the GPU cubes. See the constructor of `CPUData` for more information. */</span></div>
<div class="line"><a id="l00130" name="l00130"></a><span class="lineno">  130</span><span class="keyword">template</span> &lt;<span class="keyword">class</span> Store, <span class="keyword">class</span> IPC&gt;</div>
<div class="line"><a id="l00131" name="l00131"></a><span class="lineno">  131</span>__global__ <span class="keywordtype">void</span> allocate_gpu_cubes(GPUCube* gpu_cubes,</div>
<div class="line"><a id="l00132" name="l00132"></a><span class="lineno">  132</span>  <span class="keywordtype">size_t</span> n, Store* store, IPC* ipc)</div>
<div class="line"><a id="l00133" name="l00133"></a><span class="lineno">  133</span>{</div>
<div class="line"><a id="l00134" name="l00134"></a><span class="lineno">  134</span>  assert(threadIdx.x == 0 &amp;&amp; blockIdx.x == 0);</div>
<div class="line"><a id="l00135" name="l00135"></a><span class="lineno">  135</span>  <span class="keywordtype">size_t</span> bytes = store-&gt;get_allocator().total_bytes_allocated()</div>
<div class="line"><a id="l00136" name="l00136"></a><span class="lineno">  136</span>    + <span class="keyword">sizeof</span>(GPUCube::IStore) + <span class="keyword">sizeof</span>(GPUCube::IPC) + 1000;</div>
<div class="line"><a id="l00137" name="l00137"></a><span class="lineno">  137</span>  gpu_cubes[0].allocate(*store, *ipc, bytes + ipc-&gt;get_allocator().total_bytes_allocated(), <span class="keyword">false</span>);</div>
<div class="line"><a id="l00138" name="l00138"></a><span class="lineno">  138</span>  <span class="keywordflow">for</span>(<span class="keywordtype">int</span> i = 1; i &lt; n; ++i) {</div>
<div class="line"><a id="l00139" name="l00139"></a><span class="lineno">  139</span>    gpu_cubes[i].allocate(*gpu_cubes[0].store_gpu, *gpu_cubes[0].ipc_gpu, bytes, <span class="keyword">true</span>);</div>
<div class="line"><a id="l00140" name="l00140"></a><span class="lineno">  140</span>  }</div>
<div class="line"><a id="l00141" name="l00141"></a><span class="lineno">  141</span>}</div>
<div class="line"><a id="l00142" name="l00142"></a><span class="lineno">  142</span> </div>
<div class="line"><a id="l00143" name="l00143"></a><span class="lineno">  143</span>__global__ <span class="keywordtype">void</span> deallocate_gpu_cubes(GPUCube* gpu_cubes, <span class="keywordtype">size_t</span> n) {</div>
<div class="line"><a id="l00144" name="l00144"></a><span class="lineno">  144</span>  assert(threadIdx.x == 0 &amp;&amp; blockIdx.x == 0);</div>
<div class="line"><a id="l00145" name="l00145"></a><span class="lineno">  145</span>  <span class="keywordflow">for</span>(<span class="keywordtype">int</span> i = 0; i &lt; n; ++i) {</div>
<div class="line"><a id="l00146" name="l00146"></a><span class="lineno">  146</span>    gpu_cubes[i].deallocate();</div>
<div class="line"><a id="l00147" name="l00147"></a><span class="lineno">  147</span>  }</div>
<div class="line"><a id="l00148" name="l00148"></a><span class="lineno">  148</span>}</div>
<div class="line"><a id="l00149" name="l00149"></a><span class="lineno">  149</span><span class="comment"></span> </div>
<div class="line"><a id="l00150" name="l00150"></a><span class="lineno">  150</span><span class="comment">/** This is the data shared among all CPU threads. */</span></div>
<div class="line"><a id="l00151" name="l00151"></a><span class="lineno">  151</span><span class="keyword">struct </span>CPUData {<span class="comment"></span></div>
<div class="line"><a id="l00152" name="l00152"></a><span class="lineno">  152</span><span class="comment">  /** We generate the subproblems lazily.</span></div>
<div class="line"><a id="l00153" name="l00153"></a><span class="lineno">  153</span><span class="comment">   * Suppose we generate `2^3` subproblems, we represent the first subproblem as `000`, the second as `001`, the third as `010`, and so on.</span></div>
<div class="line"><a id="l00154" name="l00154"></a><span class="lineno">  154</span><span class="comment">   * A `0` means to turn left in the search tree, and a `1` means to turn right.</span></div>
<div class="line"><a id="l00155" name="l00155"></a><span class="lineno">  155</span><span class="comment">   * Incrementing this integer will generate the path of the next subproblem.</span></div>
<div class="line"><a id="l00156" name="l00156"></a><span class="lineno">  156</span><span class="comment">   */</span></div>
<div class="line"><a id="l00157" name="l00157"></a><span class="lineno">  157</span>  ZLB&lt;size_t, bt::atomic_memory&lt;&gt;&gt; next_subproblem;</div>
<div class="line"><a id="l00158" name="l00158"></a><span class="lineno">  158</span><span class="comment"></span> </div>
<div class="line"><a id="l00159" name="l00159"></a><span class="lineno">  159</span><span class="comment">  /** This is the best bound found so far, globally, across all threads. */</span></div>
<div class="line"><a id="l00160" name="l00160"></a><span class="lineno">  160</span>  <a class="code hl_typedef" href="common__solving_8hpp.html#ab7cbd01c4c671c527f582fffb1125923">Itv</a> best_bound;</div>
<div class="line"><a id="l00161" name="l00161"></a><span class="lineno">  161</span><span class="comment"></span> </div>
<div class="line"><a id="l00162" name="l00162"></a><span class="lineno">  162</span><span class="comment">  /** A flag to stop the threads, for example because of a timeout or CTRL-C. */</span></div>
<div class="line"><a id="l00163" name="l00163"></a><span class="lineno">  163</span>  std::atomic_flag cpu_stop;</div>
<div class="line"><a id="l00164" name="l00164"></a><span class="lineno">  164</span><span class="comment"></span> </div>
<div class="line"><a id="l00165" name="l00165"></a><span class="lineno">  165</span><span class="comment">  /** Due to multithreading, we must protect `stdout` when printing.</span></div>
<div class="line"><a id="l00166" name="l00166"></a><span class="lineno">  166</span><span class="comment">   * The model of computation in this work is lock-free, but it seems unavoidable for printing.</span></div>
<div class="line"><a id="l00167" name="l00167"></a><span class="lineno">  167</span><span class="comment">  */</span></div>
<div class="line"><a id="l00168" name="l00168"></a><span class="lineno">  168</span>  std::mutex print_lock;</div>
<div class="line"><a id="l00169" name="l00169"></a><span class="lineno">  169</span><span class="comment"></span> </div>
<div class="line"><a id="l00170" name="l00170"></a><span class="lineno">  170</span><span class="comment">  /** The initial problem is only accessible from the CPU.</span></div>
<div class="line"><a id="l00171" name="l00171"></a><span class="lineno">  171</span><span class="comment">   * It is used at the beginning to count the bytes used by the store and propagators.</span></div>
<div class="line"><a id="l00172" name="l00172"></a><span class="lineno">  172</span><span class="comment">   * And at the end, to merge all the statistics and solutions from all threads, and print them.</span></div>
<div class="line"><a id="l00173" name="l00173"></a><span class="lineno">  173</span><span class="comment">   */</span></div>
<div class="line"><a id="l00174" name="l00174"></a><span class="lineno">  174</span>  <a class="code hl_struct" href="struct_abstract_domains.html">CP&lt;Itv&gt;</a> root;</div>
<div class="line"><a id="l00175" name="l00175"></a><span class="lineno">  175</span><span class="comment"></span> </div>
<div class="line"><a id="l00176" name="l00176"></a><span class="lineno">  176</span><span class="comment">  /** For each block, how much shared memory are we using? */</span></div>
<div class="line"><a id="l00177" name="l00177"></a><span class="lineno">  177</span>  <span class="keywordtype">size_t</span> shared_mem_bytes;</div>
<div class="line"><a id="l00178" name="l00178"></a><span class="lineno">  178</span><span class="comment"></span> </div>
<div class="line"><a id="l00179" name="l00179"></a><span class="lineno">  179</span><span class="comment">  /** Each CPU thread has its own local state to solve a subproblem, called a cube. */</span></div>
<div class="line"><a id="l00180" name="l00180"></a><span class="lineno">  180</span>  bt::vector&lt;CPUCube&gt; cpu_cubes;</div>
<div class="line"><a id="l00181" name="l00181"></a><span class="lineno">  181</span><span class="comment"></span> </div>
<div class="line"><a id="l00182" name="l00182"></a><span class="lineno">  182</span><span class="comment">  /** Each GPU block has its own local state to solve a subproblem, called a cube. */</span></div>
<div class="line"><a id="l00183" name="l00183"></a><span class="lineno">  183</span>  bt::vector&lt;GPUCube, bt::managed_allocator&gt; gpu_cubes;</div>
<div class="line"><a id="l00184" name="l00184"></a><span class="lineno">  184</span><span class="comment"></span> </div>
<div class="line"><a id="l00185" name="l00185"></a><span class="lineno">  185</span><span class="comment">  /** We create as many cubes as CPU threads and GPU blocks (option `config.or_nodes`).</span></div>
<div class="line"><a id="l00186" name="l00186"></a><span class="lineno">  186</span><span class="comment">   * All CPU cubes are initialized to different subproblems, from 0 to `config.or_nodes - 1`.</span></div>
<div class="line"><a id="l00187" name="l00187"></a><span class="lineno">  187</span><span class="comment">   * Hence the next subproblem to solve is `config.or_nodes`.</span></div>
<div class="line"><a id="l00188" name="l00188"></a><span class="lineno">  188</span><span class="comment">   * The GPU cubes are initialized to the same state than the CPU cubes.</span></div>
<div class="line"><a id="l00189" name="l00189"></a><span class="lineno">  189</span><span class="comment">   * Further, we connect the CPU and GPU cubes by sharing their store of variables (`gpu_cubes[i].store_cpu` and `cpu_cubes[i].cube.store`).</span></div>
<div class="line"><a id="l00190" name="l00190"></a><span class="lineno">  190</span><span class="comment">   * Also, we share the propagators of `gpu_cubes[0].ipc_gpu` with all other cubes `gpu_cubes[i].ipc_gpu` (with i &gt;= 1).</span></div>
<div class="line"><a id="l00191" name="l00191"></a><span class="lineno">  191</span><span class="comment">  */</span></div>
<div class="line"><a id="l00192" name="l00192"></a><span class="lineno">  192</span>  CPUData(<span class="keyword">const</span> <a class="code hl_struct" href="struct_abstract_domains.html">CP&lt;Itv&gt;</a>&amp; root, <span class="keywordtype">size_t</span> shared_mem_bytes)</div>
<div class="line"><a id="l00193" name="l00193"></a><span class="lineno">  193</span>   : next_subproblem(root.config.or_nodes)</div>
<div class="line"><a id="l00194" name="l00194"></a><span class="lineno">  194</span>   , best_bound(<a class="code hl_typedef" href="common__solving_8hpp.html#ab7cbd01c4c671c527f582fffb1125923">Itv</a>::top())</div>
<div class="line"><a id="l00195" name="l00195"></a><span class="lineno">  195</span>   , root(root)</div>
<div class="line"><a id="l00196" name="l00196"></a><span class="lineno">  196</span>   , shared_mem_bytes(shared_mem_bytes)</div>
<div class="line"><a id="l00197" name="l00197"></a><span class="lineno">  197</span>   , cpu_cubes(root.config.or_nodes, this-&gt;root)</div>
<div class="line"><a id="l00198" name="l00198"></a><span class="lineno">  198</span>   , gpu_cubes(root.config.or_nodes)</div>
<div class="line"><a id="l00199" name="l00199"></a><span class="lineno">  199</span>  {</div>
<div class="line"><a id="l00200" name="l00200"></a><span class="lineno">  200</span>    cpu_stop.clear();</div>
<div class="line"><a id="l00201" name="l00201"></a><span class="lineno">  201</span>    <span class="keywordflow">for</span>(<span class="keywordtype">int</span> i = 0; i &lt; root.<a class="code hl_variable" href="struct_abstract_domains.html#a0aa5ac01e4f4a2a8b2811edca6eb8ef9">config</a>.<a class="code hl_variable" href="struct_configuration.html#a6400dfba9cd09ea3050d18c71c8d47fb">or_nodes</a>; ++i) {</div>
<div class="line"><a id="l00202" name="l00202"></a><span class="lineno">  202</span>      cpu_cubes[i].subproblem_idx = i;</div>
<div class="line"><a id="l00203" name="l00203"></a><span class="lineno">  203</span>      gpu_cubes[i].store_cpu = cpu_cubes[i].cube.store;</div>
<div class="line"><a id="l00204" name="l00204"></a><span class="lineno">  204</span>    }<span class="comment"></span></div>
<div class="line"><a id="l00205" name="l00205"></a><span class="lineno">  205</span><span class="comment">    /** This is a temporary object to initialize the first cube with the store and propagators. */</span></div>
<div class="line"><a id="l00206" name="l00206"></a><span class="lineno">  206</span>    <a class="code hl_struct" href="struct_abstract_domains.html">AbstractDomains</a>&lt;<a class="code hl_typedef" href="common__solving_8hpp.html#ab7cbd01c4c671c527f582fffb1125923">Itv</a>, bt::standard_allocator,</div>
<div class="line"><a id="l00207" name="l00207"></a><span class="lineno">  207</span>      bt::statistics_allocator&lt;UniqueLightAlloc&lt;bt::managed_allocator, 0&gt;&gt;,</div>
<div class="line"><a id="l00208" name="l00208"></a><span class="lineno">  208</span>      bt::statistics_allocator&lt;UniqueLightAlloc&lt;bt::managed_allocator, 1&gt;&gt;&gt;</div>
<div class="line"><a id="l00209" name="l00209"></a><span class="lineno">  209</span>    managed_cp(root);</div>
<div class="line"><a id="l00210" name="l00210"></a><span class="lineno">  210</span>    allocate_gpu_cubes&lt;&lt;&lt;1, 1&gt;&gt;&gt;(gpu_cubes.data(), gpu_cubes.size(), managed_cp.store.get(), managed_cp.ipc.get());</div>
<div class="line"><a id="l00211" name="l00211"></a><span class="lineno">  211</span>    CUDAEX(cudaDeviceSynchronize());</div>
<div class="line"><a id="l00212" name="l00212"></a><span class="lineno">  212</span>  }</div>
<div class="line"><a id="l00213" name="l00213"></a><span class="lineno">  213</span> </div>
<div class="line"><a id="l00214" name="l00214"></a><span class="lineno">  214</span>  ~CPUData() {</div>
<div class="line"><a id="l00215" name="l00215"></a><span class="lineno">  215</span>    deallocate_gpu_cubes&lt;&lt;&lt;1, 1&gt;&gt;&gt;(gpu_cubes.data(), gpu_cubes.size());</div>
<div class="line"><a id="l00216" name="l00216"></a><span class="lineno">  216</span>    CUDAEX(cudaDeviceSynchronize());</div>
<div class="line"><a id="l00217" name="l00217"></a><span class="lineno">  217</span>  }</div>
<div class="line"><a id="l00218" name="l00218"></a><span class="lineno">  218</span> </div>
<div class="line"><a id="l00219" name="l00219"></a><span class="lineno">  219</span>  CPUData() = <span class="keyword">delete</span>;</div>
<div class="line"><a id="l00220" name="l00220"></a><span class="lineno">  220</span>  CPUData(<span class="keyword">const</span> CPUData&amp;) = <span class="keyword">delete</span>;</div>
<div class="line"><a id="l00221" name="l00221"></a><span class="lineno">  221</span>  CPUData(CPUData&amp;&amp;) = <span class="keyword">delete</span>;</div>
<div class="line"><a id="l00222" name="l00222"></a><span class="lineno">  222</span>};</div>
<div class="line"><a id="l00223" name="l00223"></a><span class="lineno">  223</span> </div>
<div class="line"><a id="l00224" name="l00224"></a><span class="lineno">  224</span><span class="keywordtype">void</span> dive_and_solve(CPUData&amp; global, <span class="keywordtype">size_t</span> cube_idx);</div>
<div class="line"><a id="l00225" name="l00225"></a><span class="lineno">  225</span><span class="keywordtype">size_t</span> dive(CPUData&amp; global, <span class="keywordtype">size_t</span> cube_idx);</div>
<div class="line"><a id="l00226" name="l00226"></a><span class="lineno">  226</span><span class="keywordtype">void</span> solve(CPUData&amp; global, <span class="keywordtype">size_t</span> cube_idx);</div>
<div class="line"><a id="l00227" name="l00227"></a><span class="lineno">  227</span><span class="keywordtype">bool</span> propagate(CPUData&amp; global, <span class="keywordtype">size_t</span> cube_idx);</div>
<div class="line"><a id="l00228" name="l00228"></a><span class="lineno">  228</span><span class="keywordtype">bool</span> update_global_best_bound(CPUData&amp; global, <span class="keywordtype">size_t</span> cube_idx);</div>
<div class="line"><a id="l00229" name="l00229"></a><span class="lineno">  229</span><span class="keywordtype">void</span> update_local_best_bound(CPUData&amp; global, <span class="keywordtype">size_t</span> cube_idx);</div>
<div class="line"><a id="l00230" name="l00230"></a><span class="lineno">  230</span><span class="keywordtype">void</span> reduce_cubes(CPUData&amp; global);</div>
<div class="line"><a id="l00231" name="l00231"></a><span class="lineno">  231</span><span class="keywordtype">size_t</span> configure_gpu(<a class="code hl_struct" href="struct_abstract_domains.html">CP&lt;Itv&gt;</a>&amp; cp);</div>
<div class="line"><a id="l00232" name="l00232"></a><span class="lineno">  232</span>__global__ <span class="keywordtype">void</span> gpu_propagate(GPUCube* cube, <span class="keywordtype">size_t</span> shared_bytes);</div>
<div class="line"><a id="l00233" name="l00233"></a><span class="lineno">  233</span> </div>
<div class="line"><a id="l00234" name="l00234"></a><span class="lineno">  234</span><span class="preprocessor">#endif </span><span class="comment">// __CUDACC__</span></div>
<div class="line"><a id="l00235" name="l00235"></a><span class="lineno">  235</span><span class="comment"></span> </div>
<div class="line"><a id="l00236" name="l00236"></a><span class="lineno">  236</span><span class="comment">/** This is the point of entry, we preprocess the problem, create the threads solving the problem, wait for their completion or an interruption, merge and print the statistics. */</span></div>
<div class="foldopen" id="foldopen00237" data-start="{" data-end="}">
<div class="line"><a id="l00237" name="l00237"></a><span class="lineno"><a class="line" href="hybrid__dive__and__solve_8hpp.html#ab002d8e461e9e10df5c63ee20a3e33a6">  237</a></span><span class="keywordtype">void</span> <a class="code hl_function" href="hybrid__dive__and__solve_8hpp.html#ab002d8e461e9e10df5c63ee20a3e33a6">hybrid_dive_and_solve</a>(<span class="keyword">const</span> <a class="code hl_struct" href="struct_configuration.html">Configuration&lt;battery::standard_allocator&gt;</a>&amp; config)</div>
<div class="line"><a id="l00238" name="l00238"></a><span class="lineno">  238</span>{</div>
<div class="line"><a id="l00239" name="l00239"></a><span class="lineno">  239</span><span class="preprocessor">#ifndef __CUDACC__</span></div>
<div class="line"><a id="l00240" name="l00240"></a><span class="lineno">  240</span>  std::cerr &lt;&lt; <span class="stringliteral">&quot;You must use a CUDA compiler (nvcc or clang) to compile Turbo on GPU.&quot;</span> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00241" name="l00241"></a><span class="lineno">  241</span><span class="preprocessor">#else</span></div>
<div class="line"><a id="l00242" name="l00242"></a><span class="lineno">  242</span>  <span class="keyword">auto</span> start = std::chrono::high_resolution_clock::now();<span class="comment"></span></div>
<div class="line"><a id="l00243" name="l00243"></a><span class="lineno">  243</span><span class="comment">  /** We start with some preprocessing to reduce the number of variables and constraints. */</span></div>
<div class="line"><a id="l00244" name="l00244"></a><span class="lineno">  244</span>  <a class="code hl_struct" href="struct_abstract_domains.html">CP&lt;Itv&gt;</a> cp(config);</div>
<div class="line"><a id="l00245" name="l00245"></a><span class="lineno">  245</span>  cp.<a class="code hl_function" href="struct_abstract_domains.html#a9ab2a88ebb928131d7392df6c2613ddc">preprocess</a>();</div>
<div class="line"><a id="l00246" name="l00246"></a><span class="lineno">  246</span>  <span class="keywordtype">size_t</span> shared_mem_bytes = configure_gpu(cp);</div>
<div class="line"><a id="l00247" name="l00247"></a><span class="lineno">  247</span><span class="comment"></span> </div>
<div class="line"><a id="l00248" name="l00248"></a><span class="lineno">  248</span><span class="comment">  /** Block the signal CTRL-C to notify the threads if we must exit. */</span></div>
<div class="line"><a id="l00249" name="l00249"></a><span class="lineno">  249</span>  <a class="code hl_function" href="common__solving_8hpp.html#ad04619f00eb1d7deacc6f2326f0ace5e">block_signal_ctrlc</a>();</div>
<div class="line"><a id="l00250" name="l00250"></a><span class="lineno">  250</span><span class="comment"></span> </div>
<div class="line"><a id="l00251" name="l00251"></a><span class="lineno">  251</span><span class="comment">  /** This is the main data structure, we create all the data for each thread and GPU block. */</span></div>
<div class="line"><a id="l00252" name="l00252"></a><span class="lineno">  252</span>  CPUData global(cp, shared_mem_bytes);</div>
<div class="line"><a id="l00253" name="l00253"></a><span class="lineno">  253</span><span class="comment"></span> </div>
<div class="line"><a id="l00254" name="l00254"></a><span class="lineno">  254</span><span class="comment">  /** Start the algorithm in parallel with as many CPU threads as GPU blocks. */</span></div>
<div class="line"><a id="l00255" name="l00255"></a><span class="lineno">  255</span>  std::vector&lt;std::thread&gt; threads;</div>
<div class="line"><a id="l00256" name="l00256"></a><span class="lineno">  256</span>  <span class="keywordflow">for</span>(<span class="keywordtype">int</span> i = 0; i &lt; global.root.config.or_nodes; ++i) {</div>
<div class="line"><a id="l00257" name="l00257"></a><span class="lineno">  257</span>    threads.push_back(std::thread(dive_and_solve, std::ref(global), i));</div>
<div class="line"><a id="l00258" name="l00258"></a><span class="lineno">  258</span>  }</div>
<div class="line"><a id="l00259" name="l00259"></a><span class="lineno">  259</span><span class="comment"></span> </div>
<div class="line"><a id="l00260" name="l00260"></a><span class="lineno">  260</span><span class="comment">  /** We start the persistent kernel, that will perform the propagation. */</span></div>
<div class="line"><a id="l00261" name="l00261"></a><span class="lineno">  261</span>  gpu_propagate&lt;&lt;&lt;</div>
<div class="line"><a id="l00262" name="l00262"></a><span class="lineno">  262</span>      <span class="keyword">static_cast&lt;</span><span class="keywordtype">unsigned</span> <span class="keywordtype">int</span><span class="keyword">&gt;</span>(global.root.config.or_nodes),</div>
<div class="line"><a id="l00263" name="l00263"></a><span class="lineno">  263</span>      <span class="keyword">static_cast&lt;</span><span class="keywordtype">unsigned</span> <span class="keywordtype">int</span><span class="keyword">&gt;</span>(global.root.config.and_nodes),</div>
<div class="line"><a id="l00264" name="l00264"></a><span class="lineno">  264</span>      global.shared_mem_bytes&gt;&gt;&gt;</div>
<div class="line"><a id="l00265" name="l00265"></a><span class="lineno">  265</span>    (global.gpu_cubes.data(), global.shared_mem_bytes);</div>
<div class="line"><a id="l00266" name="l00266"></a><span class="lineno">  266</span><span class="comment"></span> </div>
<div class="line"><a id="l00267" name="l00267"></a><span class="lineno">  267</span><span class="comment">  /** We wait that either the solving is interrupted, or that all threads have finished. */</span></div>
<div class="line"><a id="l00268" name="l00268"></a><span class="lineno">  268</span>  <span class="keywordtype">size_t</span> terminated = 0;</div>
<div class="line"><a id="l00269" name="l00269"></a><span class="lineno">  269</span>  <span class="keywordflow">while</span>(terminated &lt; threads.size()) {</div>
<div class="line"><a id="l00270" name="l00270"></a><span class="lineno">  270</span>    <span class="keywordflow">if</span>(<a class="code hl_function" href="common__solving_8hpp.html#aceec23d67eb8f6c24010f377a52aee98">must_quit</a>() || !<a class="code hl_function" href="common__solving_8hpp.html#ae74627056bb5f54434f23cc94f5ae732">check_timeout</a>(global.root, start)) {</div>
<div class="line"><a id="l00271" name="l00271"></a><span class="lineno">  271</span>      global.cpu_stop.test_and_set();</div>
<div class="line"><a id="l00272" name="l00272"></a><span class="lineno">  272</span>      cuda::atomic_thread_fence(cuda::memory_order_seq_cst, cuda::thread_scope_system);</div>
<div class="line"><a id="l00273" name="l00273"></a><span class="lineno">  273</span>      <span class="keywordflow">break</span>;</div>
<div class="line"><a id="l00274" name="l00274"></a><span class="lineno">  274</span>    }</div>
<div class="line"><a id="l00275" name="l00275"></a><span class="lineno">  275</span>    std::this_thread::sleep_for(std::chrono::milliseconds(100));</div>
<div class="line"><a id="l00276" name="l00276"></a><span class="lineno">  276</span>    terminated = 0;</div>
<div class="line"><a id="l00277" name="l00277"></a><span class="lineno">  277</span>    <span class="keywordflow">for</span>(<span class="keywordtype">int</span> i = 0; i &lt; global.cpu_cubes.size(); ++i) {</div>
<div class="line"><a id="l00278" name="l00278"></a><span class="lineno">  278</span>      <span class="keywordflow">if</span>(global.cpu_cubes[i].finished.test()) {</div>
<div class="line"><a id="l00279" name="l00279"></a><span class="lineno">  279</span>        ++terminated;</div>
<div class="line"><a id="l00280" name="l00280"></a><span class="lineno">  280</span>      }</div>
<div class="line"><a id="l00281" name="l00281"></a><span class="lineno">  281</span>    }</div>
<div class="line"><a id="l00282" name="l00282"></a><span class="lineno">  282</span>  }</div>
<div class="line"><a id="l00283" name="l00283"></a><span class="lineno">  283</span>  <span class="keywordflow">for</span>(<span class="keyword">auto</span>&amp; t : threads) {</div>
<div class="line"><a id="l00284" name="l00284"></a><span class="lineno">  284</span>    t.join();</div>
<div class="line"><a id="l00285" name="l00285"></a><span class="lineno">  285</span>  }</div>
<div class="line"><a id="l00286" name="l00286"></a><span class="lineno">  286</span>  CUDAEX(cudaDeviceSynchronize());<span class="comment"></span></div>
<div class="line"><a id="l00287" name="l00287"></a><span class="lineno">  287</span><span class="comment">  /** We reduce all the statistics of all threads. */</span></div>
<div class="line"><a id="l00288" name="l00288"></a><span class="lineno">  288</span>  reduce_cubes(global);</div>
<div class="line"><a id="l00289" name="l00289"></a><span class="lineno">  289</span>  global.root.print_final_solution();</div>
<div class="line"><a id="l00290" name="l00290"></a><span class="lineno">  290</span>  global.root.print_mzn_statistics();</div>
<div class="line"><a id="l00291" name="l00291"></a><span class="lineno">  291</span><span class="preprocessor">#endif</span></div>
<div class="line"><a id="l00292" name="l00292"></a><span class="lineno">  292</span>}</div>
</div>
<div class="line"><a id="l00293" name="l00293"></a><span class="lineno">  293</span> </div>
<div class="line"><a id="l00294" name="l00294"></a><span class="lineno">  294</span><span class="preprocessor">#ifdef __CUDACC__</span></div>
<div class="line"><a id="l00295" name="l00295"></a><span class="lineno">  295</span><span class="comment"></span> </div>
<div class="line"><a id="l00296" name="l00296"></a><span class="lineno">  296</span><span class="comment">/** This is the main algorithm.</span></div>
<div class="line"><a id="l00297" name="l00297"></a><span class="lineno">  297</span><span class="comment"> * Each CPU thread will run one instance of this algorithm with a different `cube_idx`.</span></div>
<div class="line"><a id="l00298" name="l00298"></a><span class="lineno">  298</span><span class="comment"> * It interleaves two steps until all subproblems have been solved or we reached another stopping condition (timeout, CTRL-C, pruning conditions):</span></div>
<div class="line"><a id="l00299" name="l00299"></a><span class="lineno">  299</span><span class="comment"> *  1) Dive (function `dive`): Given a root node, follow a path in the search tree to reach a subproblem.</span></div>
<div class="line"><a id="l00300" name="l00300"></a><span class="lineno">  300</span><span class="comment"> *  2) Solve (function `solve`): Solve the subproblem using the propagate and search algorithm.</span></div>
<div class="line"><a id="l00301" name="l00301"></a><span class="lineno">  301</span><span class="comment">*/</span></div>
<div class="line"><a id="l00302" name="l00302"></a><span class="lineno">  302</span><span class="keywordtype">void</span> dive_and_solve(CPUData&amp; global, <span class="keywordtype">size_t</span> cube_idx)</div>
<div class="line"><a id="l00303" name="l00303"></a><span class="lineno">  303</span>{</div>
<div class="line"><a id="l00304" name="l00304"></a><span class="lineno">  304</span>  <span class="keywordtype">size_t</span> num_subproblems = global.root.stats.eps_num_subproblems;</div>
<div class="line"><a id="l00305" name="l00305"></a><span class="lineno">  305</span>  <span class="keywordtype">size_t</span>&amp; subproblem_idx = global.cpu_cubes[cube_idx].subproblem_idx;</div>
<div class="line"><a id="l00306" name="l00306"></a><span class="lineno">  306</span>  <span class="keyword">auto</span>&amp; cube = global.cpu_cubes[cube_idx].cube;<span class="comment"></span></div>
<div class="line"><a id="l00307" name="l00307"></a><span class="lineno">  307</span><span class="comment">  /** In each iteration, we will solve one subproblem obtained after a diving phase. */</span></div>
<div class="line"><a id="l00308" name="l00308"></a><span class="lineno">  308</span>  <span class="keywordflow">while</span>(subproblem_idx &lt; num_subproblems &amp;&amp; !global.cpu_stop.test()) {</div>
<div class="line"><a id="l00309" name="l00309"></a><span class="lineno">  309</span>    <span class="keywordflow">if</span>(global.root.config.verbose_solving) {</div>
<div class="line"><a id="l00310" name="l00310"></a><span class="lineno">  310</span>      std::lock_guard&lt;std::mutex&gt; print_guard(global.print_lock);</div>
<div class="line"><a id="l00311" name="l00311"></a><span class="lineno">  311</span>      printf(<span class="stringliteral">&quot;%% Cube %d solves subproblem num %zu\n&quot;</span>, cube_idx, subproblem_idx);</div>
<div class="line"><a id="l00312" name="l00312"></a><span class="lineno">  312</span>    }<span class="comment"></span></div>
<div class="line"><a id="l00313" name="l00313"></a><span class="lineno">  313</span><span class="comment">    /** The first step is to &quot;dive&quot; by committing to a search path. */</span></div>
<div class="line"><a id="l00314" name="l00314"></a><span class="lineno">  314</span>    <span class="keywordtype">size_t</span> remaining_depth = dive(global, cube_idx);<span class="comment"></span></div>
<div class="line"><a id="l00315" name="l00315"></a><span class="lineno">  315</span><span class="comment">    /** If we reached the subproblem without reaching a leaf node, we start the solving phase. */</span></div>
<div class="line"><a id="l00316" name="l00316"></a><span class="lineno">  316</span>    <span class="keywordflow">if</span>(remaining_depth == 0) {</div>
<div class="line"><a id="l00317" name="l00317"></a><span class="lineno">  317</span>      solve(global, cube_idx);<span class="comment"></span></div>
<div class="line"><a id="l00318" name="l00318"></a><span class="lineno">  318</span><span class="comment">      /** If we didn&#39;t stop solving because of an external interruption, we increase the number of subproblems solved. */</span></div>
<div class="line"><a id="l00319" name="l00319"></a><span class="lineno">  319</span>      <span class="keywordflow">if</span>(!global.cpu_stop.test()) {</div>
<div class="line"><a id="l00320" name="l00320"></a><span class="lineno">  320</span>        cube.stats.eps_solved_subproblems += 1;</div>
<div class="line"><a id="l00321" name="l00321"></a><span class="lineno">  321</span>      }</div>
<div class="line"><a id="l00322" name="l00322"></a><span class="lineno">  322</span>    }<span class="comment"></span></div>
<div class="line"><a id="l00323" name="l00323"></a><span class="lineno">  323</span><span class="comment">    /** We reached a leaf node before the subproblem was reached, it means a whole subtree should be skipped. */</span></div>
<div class="line"><a id="l00324" name="l00324"></a><span class="lineno">  324</span>    <span class="keywordflow">else</span> <span class="keywordflow">if</span>(!global.cpu_stop.test()) {<span class="comment"></span></div>
<div class="line"><a id="l00325" name="l00325"></a><span class="lineno">  325</span><span class="comment">      /** To skip all the paths of the subtree obtained, we perform bitwise operations.</span></div>
<div class="line"><a id="l00326" name="l00326"></a><span class="lineno">  326</span><span class="comment">       * Suppose the current path is &quot;00&quot; turn left two times, and the following search tree:</span></div>
<div class="line"><a id="l00327" name="l00327"></a><span class="lineno">  327</span><span class="comment">       *         *         depth = 0</span></div>
<div class="line"><a id="l00328" name="l00328"></a><span class="lineno">  328</span><span class="comment">       *        / \</span></div>
<div class="line"><a id="l00329" name="l00329"></a><span class="lineno">  329</span><span class="comment">       *      0    1       depth = 1</span></div>
<div class="line"><a id="l00330" name="l00330"></a><span class="lineno">  330</span><span class="comment">       *    / \   / \</span></div>
<div class="line"><a id="l00331" name="l00331"></a><span class="lineno">  331</span><span class="comment">       *   00 01 10 11     depth = 2</span></div>
<div class="line"><a id="l00332" name="l00332"></a><span class="lineno">  332</span><span class="comment">       *</span></div>
<div class="line"><a id="l00333" name="l00333"></a><span class="lineno">  333</span><span class="comment">       * If we detect a leaf node at depth 1, after only one left turn, we must skip the remaining of the subtree, in particular to avoid exploring the path &quot;01&quot;.</span></div>
<div class="line"><a id="l00334" name="l00334"></a><span class="lineno">  334</span><span class="comment">       * To achieve that, we take the current path &quot;00&quot;, shift it to the right by 1 (essentially erasing the path that has not been explored), increment it to go to the next subtree (at the same depth), and shift it back to the left to reach the first subproblem of the subtree.</span></div>
<div class="line"><a id="l00335" name="l00335"></a><span class="lineno">  335</span><span class="comment">       * Cool huh?</span></div>
<div class="line"><a id="l00336" name="l00336"></a><span class="lineno">  336</span><span class="comment">       */</span></div>
<div class="line"><a id="l00337" name="l00337"></a><span class="lineno">  337</span>      <span class="keywordtype">size_t</span> next_subproblem_idx = ((subproblem_idx &gt;&gt; remaining_depth) + <span class="keywordtype">size_t</span>{1}) &lt;&lt; remaining_depth;</div>
<div class="line"><a id="l00338" name="l00338"></a><span class="lineno">  338</span>      global.next_subproblem.meet(ZLB&lt;size_t, bt::local_memory&gt;(next_subproblem_idx));<span class="comment"></span></div>
<div class="line"><a id="l00339" name="l00339"></a><span class="lineno">  339</span><span class="comment">      /** It is possible that other threads skip similar subtrees.</span></div>
<div class="line"><a id="l00340" name="l00340"></a><span class="lineno">  340</span><span class="comment">        * Hence, we only count the subproblems skipped by the thread solving the left most subproblem. */</span></div>
<div class="line"><a id="l00341" name="l00341"></a><span class="lineno">  341</span>      <span class="keywordflow">if</span>((subproblem_idx &amp; ((<span class="keywordtype">size_t</span>{1} &lt;&lt; remaining_depth) - <span class="keywordtype">size_t</span>{1})) == <span class="keywordtype">size_t</span>{0}) {</div>
<div class="line"><a id="l00342" name="l00342"></a><span class="lineno">  342</span>        cube.stats.eps_skipped_subproblems += next_subproblem_idx - subproblem_idx;</div>
<div class="line"><a id="l00343" name="l00343"></a><span class="lineno">  343</span>      }</div>
<div class="line"><a id="l00344" name="l00344"></a><span class="lineno">  344</span>    }<span class="comment"></span></div>
<div class="line"><a id="l00345" name="l00345"></a><span class="lineno">  345</span><span class="comment">    /** We prepare the cube to solve the next problem.</span></div>
<div class="line"><a id="l00346" name="l00346"></a><span class="lineno">  346</span><span class="comment">     * We restore the search tree to the root, and reset the EPS search strategy.</span></div>
<div class="line"><a id="l00347" name="l00347"></a><span class="lineno">  347</span><span class="comment">     * We also update the subproblem index to the next subproblem to solve. */</span></div>
<div class="line"><a id="l00348" name="l00348"></a><span class="lineno">  348</span>    <span class="keywordflow">if</span>(!global.cpu_stop.test()) {<span class="comment"></span></div>
<div class="line"><a id="l00349" name="l00349"></a><span class="lineno">  349</span><span class="comment">      /** To avoid that several cubes solve the same subproblem, we use an atomic post-increment. */</span></div>
<div class="line"><a id="l00350" name="l00350"></a><span class="lineno">  350</span>      subproblem_idx = global.next_subproblem.atomic()++;<span class="comment"></span></div>
<div class="line"><a id="l00351" name="l00351"></a><span class="lineno">  351</span><span class="comment">      /** The following commented code is completely valid and does not use atomic post-increment.</span></div>
<div class="line"><a id="l00352" name="l00352"></a><span class="lineno">  352</span><span class="comment">       * But honestly, we kinda need more performance so... let&#39;s avoid reexploring subproblems. */</span></div>
<div class="line"><a id="l00353" name="l00353"></a><span class="lineno">  353</span>      <span class="comment">// subproblem_idx = global.next_subproblem.value();</span></div>
<div class="line"><a id="l00354" name="l00354"></a><span class="lineno">  354</span>      <span class="comment">// global.next_subproblem.meet(ZLB&lt;size_t, bt::local_memory&gt;(subproblem_idx + size_t{1}));</span></div>
<div class="line"><a id="l00355" name="l00355"></a><span class="lineno">  355</span>      <span class="keywordflow">if</span>(subproblem_idx &lt; num_subproblems) {</div>
<div class="line"><a id="l00356" name="l00356"></a><span class="lineno">  356</span>        cube.search_tree-&gt;restore(global.cpu_cubes[cube_idx].root_snapshot);</div>
<div class="line"><a id="l00357" name="l00357"></a><span class="lineno">  357</span>        cube.eps_split-&gt;reset();</div>
<div class="line"><a id="l00358" name="l00358"></a><span class="lineno">  358</span>      }</div>
<div class="line"><a id="l00359" name="l00359"></a><span class="lineno">  359</span>    }</div>
<div class="line"><a id="l00360" name="l00360"></a><span class="lineno">  360</span>  }<span class="comment"></span></div>
<div class="line"><a id="l00361" name="l00361"></a><span class="lineno">  361</span><span class="comment">  /** If we did not get interrupted, this thread has explored all available subproblems.</span></div>
<div class="line"><a id="l00362" name="l00362"></a><span class="lineno">  362</span><span class="comment">   * We record this information in `num_blocks_done` simply because it helps to detect unbalanced workloads (many threads finished but not some others).</span></div>
<div class="line"><a id="l00363" name="l00363"></a><span class="lineno">  363</span><span class="comment">   */</span></div>
<div class="line"><a id="l00364" name="l00364"></a><span class="lineno">  364</span>  <span class="keywordflow">if</span>(!global.cpu_stop.test()) {</div>
<div class="line"><a id="l00365" name="l00365"></a><span class="lineno">  365</span>    cube.stats.num_blocks_done = 1;</div>
<div class="line"><a id="l00366" name="l00366"></a><span class="lineno">  366</span>  }<span class="comment"></span></div>
<div class="line"><a id="l00367" name="l00367"></a><span class="lineno">  367</span><span class="comment">  /** We signal to the GPU kernel that this block must terminate.</span></div>
<div class="line"><a id="l00368" name="l00368"></a><span class="lineno">  368</span><span class="comment">   * The GPU block is necessarily waiting on `ready_to_propagate`, hence by setting `stop` first, using a memory fence, we ensure the GPU block is going to see it must stop.</span></div>
<div class="line"><a id="l00369" name="l00369"></a><span class="lineno">  369</span><span class="comment">  */</span></div>
<div class="line"><a id="l00370" name="l00370"></a><span class="lineno">  370</span>  global.gpu_cubes[cube_idx].stop.test_and_set();</div>
<div class="line"><a id="l00371" name="l00371"></a><span class="lineno">  371</span>  cuda::atomic_thread_fence(cuda::memory_order_seq_cst, cuda::thread_scope_system);</div>
<div class="line"><a id="l00372" name="l00372"></a><span class="lineno">  372</span>  global.gpu_cubes[cube_idx].ready_to_propagate.test_and_set(cuda::std::memory_order_seq_cst);</div>
<div class="line"><a id="l00373" name="l00373"></a><span class="lineno">  373</span>  global.gpu_cubes[cube_idx].ready_to_propagate.notify_one();</div>
<div class="line"><a id="l00374" name="l00374"></a><span class="lineno">  374</span><span class="comment"></span> </div>
<div class="line"><a id="l00375" name="l00375"></a><span class="lineno">  375</span><span class="comment">  /** We signal to the main thread that we have finished our work. */</span></div>
<div class="line"><a id="l00376" name="l00376"></a><span class="lineno">  376</span>  global.cpu_cubes[cube_idx].finished.test_and_set();</div>
<div class="line"><a id="l00377" name="l00377"></a><span class="lineno">  377</span>}</div>
<div class="line"><a id="l00378" name="l00378"></a><span class="lineno">  378</span><span class="comment"></span> </div>
<div class="line"><a id="l00379" name="l00379"></a><span class="lineno">  379</span><span class="comment">/** Given a root problem, we follow a predefined path in the search tree to reach a subproblem.</span></div>
<div class="line"><a id="l00380" name="l00380"></a><span class="lineno">  380</span><span class="comment"> * This is call the &quot;dive&quot; operation.</span></div>
<div class="line"><a id="l00381" name="l00381"></a><span class="lineno">  381</span><span class="comment"> * The path is given by `subproblem_idx` in the CPU cube (see `CPUData::next_subproblem` for more info).</span></div>
<div class="line"><a id="l00382" name="l00382"></a><span class="lineno">  382</span><span class="comment"> * For all dives, the initial problem must be the same and the EPS search strategy must be static (always splitting the tree in the same way).</span></div>
<div class="line"><a id="l00383" name="l00383"></a><span class="lineno">  383</span><span class="comment"> * Therefore, don&#39;t be tempted to add the objective to the initial problem because it might lead to ignoring some subproblems since the splitting decisions will differ.</span></div>
<div class="line"><a id="l00384" name="l00384"></a><span class="lineno">  384</span><span class="comment"> *</span></div>
<div class="line"><a id="l00385" name="l00385"></a><span class="lineno">  385</span><span class="comment"> * \return The remaining depth of the path if we reach a leaf node before the end of the path.</span></div>
<div class="line"><a id="l00386" name="l00386"></a><span class="lineno">  386</span><span class="comment"> */</span></div>
<div class="line"><a id="l00387" name="l00387"></a><span class="lineno">  387</span><span class="keywordtype">size_t</span> dive(CPUData&amp; global, <span class="keywordtype">size_t</span> cube_idx) {</div>
<div class="line"><a id="l00388" name="l00388"></a><span class="lineno">  388</span>  <span class="keyword">auto</span>&amp; cube = global.cpu_cubes[cube_idx].cube;</div>
<div class="line"><a id="l00389" name="l00389"></a><span class="lineno">  389</span>  <span class="keywordtype">bool</span> stop_diving = <span class="keyword">false</span>;</div>
<div class="line"><a id="l00390" name="l00390"></a><span class="lineno">  390</span>  <span class="keywordtype">size_t</span> remaining_depth = cube.config.subproblems_power;<span class="comment"></span></div>
<div class="line"><a id="l00391" name="l00391"></a><span class="lineno">  391</span><span class="comment">  /** The number of iterations depends on the length of the diving path. */</span></div>
<div class="line"><a id="l00392" name="l00392"></a><span class="lineno">  392</span>  <span class="keywordflow">while</span>(remaining_depth &gt; 0 &amp;&amp; !stop_diving &amp;&amp; !global.cpu_stop.test()) {</div>
<div class="line"><a id="l00393" name="l00393"></a><span class="lineno">  393</span>    remaining_depth--;</div>
<div class="line"><a id="l00394" name="l00394"></a><span class="lineno">  394</span>    <span class="keywordtype">bool</span> is_leaf_node = propagate(global, cube_idx);<span class="comment"></span></div>
<div class="line"><a id="l00395" name="l00395"></a><span class="lineno">  395</span><span class="comment">    /** If we reach a leaf node before the end of the path, we stop and the remaining depth is reported to the caller. */</span></div>
<div class="line"><a id="l00396" name="l00396"></a><span class="lineno">  396</span>    <span class="keywordflow">if</span>(is_leaf_node) {</div>
<div class="line"><a id="l00397" name="l00397"></a><span class="lineno">  397</span>      stop_diving = <span class="keyword">true</span>;</div>
<div class="line"><a id="l00398" name="l00398"></a><span class="lineno">  398</span>    }</div>
<div class="line"><a id="l00399" name="l00399"></a><span class="lineno">  399</span>    <span class="keywordflow">else</span> {<span class="comment"></span></div>
<div class="line"><a id="l00400" name="l00400"></a><span class="lineno">  400</span><span class="comment">      /** We create two branches according to the EPS search strategy. */</span></div>
<div class="line"><a id="l00401" name="l00401"></a><span class="lineno">  401</span>      <span class="keyword">auto</span> branches = cube.eps_split-&gt;split();</div>
<div class="line"><a id="l00402" name="l00402"></a><span class="lineno">  402</span>      assert(branches.size() == 2);<span class="comment"></span></div>
<div class="line"><a id="l00403" name="l00403"></a><span class="lineno">  403</span><span class="comment">      /** We commit to one of the branches depending on the current value on the path.</span></div>
<div class="line"><a id="l00404" name="l00404"></a><span class="lineno">  404</span><span class="comment">       * Suppose the depth is 3, the path is &quot;010&quot; we are currently at `remaining_depth = 1`.</span></div>
<div class="line"><a id="l00405" name="l00405"></a><span class="lineno">  405</span><span class="comment">       * We must extract the bit &quot;1&quot;, and we do so by standard bitwise manipulation.</span></div>
<div class="line"><a id="l00406" name="l00406"></a><span class="lineno">  406</span><span class="comment">       * Whenever the branch_idx is 0 means to take the left branch, and 1 means to take the right branch.</span></div>
<div class="line"><a id="l00407" name="l00407"></a><span class="lineno">  407</span><span class="comment">       */</span></div>
<div class="line"><a id="l00408" name="l00408"></a><span class="lineno">  408</span>      <span class="keywordtype">size_t</span> branch_idx = (global.cpu_cubes[cube_idx].subproblem_idx &amp; (<span class="keywordtype">size_t</span>{1} &lt;&lt; remaining_depth)) &gt;&gt; remaining_depth;<span class="comment"></span></div>
<div class="line"><a id="l00409" name="l00409"></a><span class="lineno">  409</span><span class="comment">      /** We immediately commit to the branch.</span></div>
<div class="line"><a id="l00410" name="l00410"></a><span class="lineno">  410</span><span class="comment">       * It has the effect of reducing the domain of the variables in `cube.store` (and `gpu_cube.store_cpu` since they are aliased).</span></div>
<div class="line"><a id="l00411" name="l00411"></a><span class="lineno">  411</span><span class="comment">       */</span></div>
<div class="line"><a id="l00412" name="l00412"></a><span class="lineno">  412</span>      cube.ipc-&gt;deduce(branches[branch_idx]);</div>
<div class="line"><a id="l00413" name="l00413"></a><span class="lineno">  413</span>    }</div>
<div class="line"><a id="l00414" name="l00414"></a><span class="lineno">  414</span>  }</div>
<div class="line"><a id="l00415" name="l00415"></a><span class="lineno">  415</span>  <span class="keywordflow">return</span> remaining_depth;</div>
<div class="line"><a id="l00416" name="l00416"></a><span class="lineno">  416</span>}</div>
<div class="line"><a id="l00417" name="l00417"></a><span class="lineno">  417</span><span class="comment"></span> </div>
<div class="line"><a id="l00418" name="l00418"></a><span class="lineno">  418</span><span class="comment">/** We solve a cube using the propagate and search algorithm.</span></div>
<div class="line"><a id="l00419" name="l00419"></a><span class="lineno">  419</span><span class="comment"> * We explore the whole search tree of the cube, only stopping earlier due to pruning conditions or external stop signal (e.g. `global.cpu_stop`).</span></div>
<div class="line"><a id="l00420" name="l00420"></a><span class="lineno">  420</span><span class="comment"> */</span></div>
<div class="line"><a id="l00421" name="l00421"></a><span class="lineno">  421</span><span class="keywordtype">void</span> solve(CPUData&amp; global, <span class="keywordtype">size_t</span> cube_idx) {</div>
<div class="line"><a id="l00422" name="l00422"></a><span class="lineno">  422</span>  <span class="keyword">auto</span>&amp; cpu_cube = global.cpu_cubes[cube_idx].cube;</div>
<div class="line"><a id="l00423" name="l00423"></a><span class="lineno">  423</span>  <span class="keywordtype">bool</span> has_changed = <span class="keyword">true</span>;</div>
<div class="line"><a id="l00424" name="l00424"></a><span class="lineno">  424</span>  <span class="keywordflow">while</span>(has_changed &amp;&amp; !global.cpu_stop.test()) {<span class="comment"></span></div>
<div class="line"><a id="l00425" name="l00425"></a><span class="lineno">  425</span><span class="comment">    /** Before propagating, we update the local bound with the best known global bound. */</span></div>
<div class="line"><a id="l00426" name="l00426"></a><span class="lineno">  426</span>    update_local_best_bound(global, cube_idx);<span class="comment"></span></div>
<div class="line"><a id="l00427" name="l00427"></a><span class="lineno">  427</span><span class="comment">    /** We propagate on GPU, and manage the leaf nodes (solution and failed nodes). */</span></div>
<div class="line"><a id="l00428" name="l00428"></a><span class="lineno">  428</span>    propagate(global, cube_idx);<span class="comment"></span></div>
<div class="line"><a id="l00429" name="l00429"></a><span class="lineno">  429</span><span class="comment">    /** We pop a new node from the search tree, ready to explore.</span></div>
<div class="line"><a id="l00430" name="l00430"></a><span class="lineno">  430</span><span class="comment">     * If the search tree becomes empty, `has_changed` will be `false`.</span></div>
<div class="line"><a id="l00431" name="l00431"></a><span class="lineno">  431</span><span class="comment">     */</span></div>
<div class="line"><a id="l00432" name="l00432"></a><span class="lineno">  432</span>    has_changed = cpu_cube.search_tree-&gt;deduce();</div>
<div class="line"><a id="l00433" name="l00433"></a><span class="lineno">  433</span>  }</div>
<div class="line"><a id="l00434" name="l00434"></a><span class="lineno">  434</span>}</div>
<div class="line"><a id="l00435" name="l00435"></a><span class="lineno">  435</span><span class="comment"></span> </div>
<div class="line"><a id="l00436" name="l00436"></a><span class="lineno">  436</span><span class="comment">/** Propagate the cube `cube_idx` on the GPU.</span></div>
<div class="line"><a id="l00437" name="l00437"></a><span class="lineno">  437</span><span class="comment"> * Check if we reached a leaf node (solution or failed) on the CPU.</span></div>
<div class="line"><a id="l00438" name="l00438"></a><span class="lineno">  438</span><span class="comment"> * Branching on unknown nodes is a task left to the caller.</span></div>
<div class="line"><a id="l00439" name="l00439"></a><span class="lineno">  439</span><span class="comment"> *</span></div>
<div class="line"><a id="l00440" name="l00440"></a><span class="lineno">  440</span><span class="comment"> * \return `true` if we reached a leaf node.</span></div>
<div class="line"><a id="l00441" name="l00441"></a><span class="lineno">  441</span><span class="comment"> */</span></div>
<div class="line"><a id="l00442" name="l00442"></a><span class="lineno">  442</span><span class="keywordtype">bool</span> propagate(CPUData&amp; global, <span class="keywordtype">size_t</span> cube_idx) {</div>
<div class="line"><a id="l00443" name="l00443"></a><span class="lineno">  443</span>  <span class="keyword">auto</span>&amp; cpu_cube = global.cpu_cubes[cube_idx].cube;</div>
<div class="line"><a id="l00444" name="l00444"></a><span class="lineno">  444</span>  <span class="keyword">auto</span>&amp; gpu_cube = global.gpu_cubes[cube_idx];</div>
<div class="line"><a id="l00445" name="l00445"></a><span class="lineno">  445</span>  <span class="keywordtype">bool</span> is_leaf_node = <span class="keyword">false</span>;</div>
<div class="line"><a id="l00446" name="l00446"></a><span class="lineno">  446</span><span class="comment"></span> </div>
<div class="line"><a id="l00447" name="l00447"></a><span class="lineno">  447</span><span class="comment">  /** We signal to the GPU that it can propagate the current node.</span></div>
<div class="line"><a id="l00448" name="l00448"></a><span class="lineno">  448</span><span class="comment">   * Thereafter, we immediately wait for the GPU to finish the propagation before performing the search step.</span></div>
<div class="line"><a id="l00449" name="l00449"></a><span class="lineno">  449</span><span class="comment">   */</span></div>
<div class="line"><a id="l00450" name="l00450"></a><span class="lineno">  450</span>  cuda::atomic_thread_fence(cuda::memory_order_seq_cst, cuda::thread_scope_system);</div>
<div class="line"><a id="l00451" name="l00451"></a><span class="lineno">  451</span>  gpu_cube.ready_to_propagate.test_and_set(cuda::std::memory_order_seq_cst);</div>
<div class="line"><a id="l00452" name="l00452"></a><span class="lineno">  452</span>  gpu_cube.ready_to_propagate.notify_one();</div>
<div class="line"><a id="l00453" name="l00453"></a><span class="lineno">  453</span>  gpu_cube.ready_to_search.wait(<span class="keyword">false</span>, cuda::std::memory_order_seq_cst);</div>
<div class="line"><a id="l00454" name="l00454"></a><span class="lineno">  454</span>  gpu_cube.ready_to_search.clear();</div>
<div class="line"><a id="l00455" name="l00455"></a><span class="lineno">  455</span><span class="comment"></span> </div>
<div class="line"><a id="l00456" name="l00456"></a><span class="lineno">  456</span><span class="comment">  /** `on_node` updates the statistics and verifies whether we should stop (e.g. option `--cutnodes`). */</span></div>
<div class="line"><a id="l00457" name="l00457"></a><span class="lineno">  457</span>  <span class="keywordtype">bool</span> is_pruned = cpu_cube.on_node();<span class="comment"></span></div>
<div class="line"><a id="l00458" name="l00458"></a><span class="lineno">  458</span><span class="comment">  /** If the abstract domain is `bottom`, we reached a leaf node where the problem is unsatisfiable. */</span></div>
<div class="line"><a id="l00459" name="l00459"></a><span class="lineno">  459</span>  <span class="keywordflow">if</span>(cpu_cube.ipc-&gt;is_bot()) {</div>
<div class="line"><a id="l00460" name="l00460"></a><span class="lineno">  460</span>    is_leaf_node = <span class="keyword">true</span>;</div>
<div class="line"><a id="l00461" name="l00461"></a><span class="lineno">  461</span>    cpu_cube.on_failed_node();</div>
<div class="line"><a id="l00462" name="l00462"></a><span class="lineno">  462</span>  }<span class="comment"></span></div>
<div class="line"><a id="l00463" name="l00463"></a><span class="lineno">  463</span><span class="comment">  /** When the problem is &quot;extractable&quot;, then all variables are assigned to a single value.</span></div>
<div class="line"><a id="l00464" name="l00464"></a><span class="lineno">  464</span><span class="comment">   * It means that we have reached a solution.</span></div>
<div class="line"><a id="l00465" name="l00465"></a><span class="lineno">  465</span><span class="comment">   */</span></div>
<div class="line"><a id="l00466" name="l00466"></a><span class="lineno">  466</span>  <span class="keywordflow">else</span> <span class="keywordflow">if</span>(cpu_cube.search_tree-&gt;template is_extractable&lt;AtomicExtraction&gt;()) {</div>
<div class="line"><a id="l00467" name="l00467"></a><span class="lineno">  467</span>    is_leaf_node = <span class="keyword">true</span>;<span class="comment"></span></div>
<div class="line"><a id="l00468" name="l00468"></a><span class="lineno">  468</span><span class="comment">    /** We save the new best solution found.</span></div>
<div class="line"><a id="l00469" name="l00469"></a><span class="lineno">  469</span><span class="comment">     * The &quot;branch-and-bound&quot; (bab) abstract domain has a local store of variable to store the best solution.</span></div>
<div class="line"><a id="l00470" name="l00470"></a><span class="lineno">  470</span><span class="comment">     * It adds a new bound constraint to the root of the search tree, such that, on backtracking the best bound is enforced.</span></div>
<div class="line"><a id="l00471" name="l00471"></a><span class="lineno">  471</span><span class="comment">     */</span></div>
<div class="line"><a id="l00472" name="l00472"></a><span class="lineno">  472</span>    cpu_cube.bab-&gt;deduce();</div>
<div class="line"><a id="l00473" name="l00473"></a><span class="lineno">  473</span>    <span class="keywordtype">bool</span> print_solution = cpu_cube.is_printing_intermediate_sol();</div>
<div class="line"><a id="l00474" name="l00474"></a><span class="lineno">  474</span>    <span class="keywordflow">if</span>(cpu_cube.bab-&gt;is_optimization()) {<span class="comment"></span></div>
<div class="line"><a id="l00475" name="l00475"></a><span class="lineno">  475</span><span class="comment">      /** We share the new best bound with the other cubes. */</span></div>
<div class="line"><a id="l00476" name="l00476"></a><span class="lineno">  476</span>      print_solution &amp;= update_global_best_bound(global, cube_idx);</div>
<div class="line"><a id="l00477" name="l00477"></a><span class="lineno">  477</span>    }<span class="comment"></span></div>
<div class="line"><a id="l00478" name="l00478"></a><span class="lineno">  478</span><span class="comment">    /** If we print all intermediate solutions, and really found a better bound (no other thread found a better one meanwhile), we print the current solution. */</span></div>
<div class="line"><a id="l00479" name="l00479"></a><span class="lineno">  479</span>    <span class="keywordflow">if</span>(print_solution) {</div>
<div class="line"><a id="l00480" name="l00480"></a><span class="lineno">  480</span>      cpu_cube.print_solution();</div>
<div class="line"><a id="l00481" name="l00481"></a><span class="lineno">  481</span>    }<span class="comment"></span></div>
<div class="line"><a id="l00482" name="l00482"></a><span class="lineno">  482</span><span class="comment">    /** We update the statistics, and check if we must terminate (e.g. we stop after N solutions). */</span></div>
<div class="line"><a id="l00483" name="l00483"></a><span class="lineno">  483</span>    is_pruned |= cpu_cube.update_solution_stats();</div>
<div class="line"><a id="l00484" name="l00484"></a><span class="lineno">  484</span>  }</div>
<div class="line"><a id="l00485" name="l00485"></a><span class="lineno">  485</span>  <span class="keywordflow">if</span>(is_pruned) {<span class="comment"></span></div>
<div class="line"><a id="l00486" name="l00486"></a><span class="lineno">  486</span><span class="comment">    /** We notify all threads that we must stop. */</span></div>
<div class="line"><a id="l00487" name="l00487"></a><span class="lineno">  487</span>    global.cpu_stop.test_and_set();</div>
<div class="line"><a id="l00488" name="l00488"></a><span class="lineno">  488</span>  }</div>
<div class="line"><a id="l00489" name="l00489"></a><span class="lineno">  489</span>  <span class="keywordflow">return</span> is_leaf_node;</div>
<div class="line"><a id="l00490" name="l00490"></a><span class="lineno">  490</span>}</div>
<div class="line"><a id="l00491" name="l00491"></a><span class="lineno">  491</span><span class="comment"></span> </div>
<div class="line"><a id="l00492" name="l00492"></a><span class="lineno">  492</span><span class="comment">/** Each block of this kernel executes the propagation loop on the GPU until a fixpoint is reached.</span></div>
<div class="line"><a id="l00493" name="l00493"></a><span class="lineno">  493</span><span class="comment"> * 1) Transfer the store of variables from the CPU to the GPU.</span></div>
<div class="line"><a id="l00494" name="l00494"></a><span class="lineno">  494</span><span class="comment"> * 2) Execute the fixpoint engine.</span></div>
<div class="line"><a id="l00495" name="l00495"></a><span class="lineno">  495</span><span class="comment"> * 3) Transfer the store of variables from the GPU to the CPU.</span></div>
<div class="line"><a id="l00496" name="l00496"></a><span class="lineno">  496</span><span class="comment"> *</span></div>
<div class="line"><a id="l00497" name="l00497"></a><span class="lineno">  497</span><span class="comment"> * These three steps are repeated until `cpu_stop` becomes `true`.</span></div>
<div class="line"><a id="l00498" name="l00498"></a><span class="lineno">  498</span><span class="comment"> * Each block is continuously processing a stream of nodes coming from the CPU.</span></div>
<div class="line"><a id="l00499" name="l00499"></a><span class="lineno">  499</span><span class="comment"> *</span></div>
<div class="line"><a id="l00500" name="l00500"></a><span class="lineno">  500</span><span class="comment"> * The size of `gpu_cubes` must be equal to the number of blocks.</span></div>
<div class="line"><a id="l00501" name="l00501"></a><span class="lineno">  501</span><span class="comment"> */</span></div>
<div class="line"><a id="l00502" name="l00502"></a><span class="lineno">  502</span>__global__ <span class="keywordtype">void</span> gpu_propagate(GPUCube* gpu_cubes, <span class="keywordtype">size_t</span> shared_bytes) {</div>
<div class="line"><a id="l00503" name="l00503"></a><span class="lineno">  503</span>  <span class="keyword">extern</span> __shared__ <span class="keywordtype">unsigned</span> <span class="keywordtype">char</span> shared_mem[];</div>
<div class="line"><a id="l00504" name="l00504"></a><span class="lineno">  504</span>  <span class="keyword">auto</span> group = cooperative_groups::this_thread_block();</div>
<div class="line"><a id="l00505" name="l00505"></a><span class="lineno">  505</span>  GPUCube&amp; cube = gpu_cubes[blockIdx.x];</div>
<div class="line"><a id="l00506" name="l00506"></a><span class="lineno">  506</span><span class="comment"></span> </div>
<div class="line"><a id="l00507" name="l00507"></a><span class="lineno">  507</span><span class="comment">  /** We start by initializing the structures in shared memory (fixpoint loop engine, store of variables). */</span></div>
<div class="line"><a id="l00508" name="l00508"></a><span class="lineno">  508</span>  <span class="keyword">using </span>FPEngine = BlockAsynchronousIterationGPU&lt;bt::pool_allocator&gt;;</div>
<div class="line"><a id="l00509" name="l00509"></a><span class="lineno">  509</span>  bt::unique_ptr&lt;bt::pool_allocator, bt::global_allocator&gt; shared_mem_pool_ptr;</div>
<div class="line"><a id="l00510" name="l00510"></a><span class="lineno">  510</span>  bt::pool_allocator&amp; shared_mem_pool = bt::make_unique_block(shared_mem_pool_ptr, shared_mem, shared_bytes);</div>
<div class="line"><a id="l00511" name="l00511"></a><span class="lineno">  511</span>  <span class="comment">// If we booked more than the default shared memory, it means we allocate the store in shared memory.</span></div>
<div class="line"><a id="l00512" name="l00512"></a><span class="lineno">  512</span>  <span class="keywordflow">if</span>(threadIdx.x == 0 &amp;&amp; shared_bytes &gt; DEFAULT_SHARED_MEM_BYTES) {</div>
<div class="line"><a id="l00513" name="l00513"></a><span class="lineno">  513</span>    cube.store_gpu-&gt;reset_data(shared_mem_pool);</div>
<div class="line"><a id="l00514" name="l00514"></a><span class="lineno">  514</span>  }</div>
<div class="line"><a id="l00515" name="l00515"></a><span class="lineno">  515</span>  <span class="comment">// No need to sync here, make_unique_block already contains sync.</span></div>
<div class="line"><a id="l00516" name="l00516"></a><span class="lineno">  516</span>  bt::unique_ptr&lt;FPEngine, bt::global_allocator&gt; fp_engine_ptr;</div>
<div class="line"><a id="l00517" name="l00517"></a><span class="lineno">  517</span>  FPEngine&amp; fp_engine = bt::make_unique_block(fp_engine_ptr, group, shared_mem_pool);</div>
<div class="line"><a id="l00518" name="l00518"></a><span class="lineno">  518</span>  group.sync();</div>
<div class="line"><a id="l00519" name="l00519"></a><span class="lineno">  519</span> </div>
<div class="line"><a id="l00520" name="l00520"></a><span class="lineno">  520</span>  <span class="keywordflow">while</span>(<span class="keyword">true</span>) {<span class="comment"></span></div>
<div class="line"><a id="l00521" name="l00521"></a><span class="lineno">  521</span><span class="comment">    /** We wait that the CPU notifies us the store is ready to be copied and propagated. */</span></div>
<div class="line"><a id="l00522" name="l00522"></a><span class="lineno">  522</span>    <span class="keywordflow">if</span>(threadIdx.x == 0) {</div>
<div class="line"><a id="l00523" name="l00523"></a><span class="lineno">  523</span>      cube.ready_to_propagate.wait(<span class="keyword">false</span>, cuda::std::memory_order_seq_cst);</div>
<div class="line"><a id="l00524" name="l00524"></a><span class="lineno">  524</span>      cube.ready_to_propagate.clear();</div>
<div class="line"><a id="l00525" name="l00525"></a><span class="lineno">  525</span>    }</div>
<div class="line"><a id="l00526" name="l00526"></a><span class="lineno">  526</span>    group.sync();</div>
<div class="line"><a id="l00527" name="l00527"></a><span class="lineno">  527</span>    <span class="keywordflow">if</span>(cube.stop.test()) {</div>
<div class="line"><a id="l00528" name="l00528"></a><span class="lineno">  528</span>      <span class="keywordflow">break</span>;</div>
<div class="line"><a id="l00529" name="l00529"></a><span class="lineno">  529</span>    }<span class="comment"></span></div>
<div class="line"><a id="l00530" name="l00530"></a><span class="lineno">  530</span><span class="comment">    /** We copy the CPU store into the GPU memory. */</span></div>
<div class="line"><a id="l00531" name="l00531"></a><span class="lineno">  531</span>    cube.store_cpu-&gt;copy_to(group, *cube.store_gpu);<span class="comment"></span></div>
<div class="line"><a id="l00532" name="l00532"></a><span class="lineno">  532</span><span class="comment">    /** This is the main propagation algorithm: the current node is propagated in parallel. */</span></div>
<div class="line"><a id="l00533" name="l00533"></a><span class="lineno">  533</span>    <span class="keywordtype">size_t</span> fp_iterations = fp_engine.fixpoint(*(cube.ipc_gpu));</div>
<div class="line"><a id="l00534" name="l00534"></a><span class="lineno">  534</span>    <span class="comment">// No need to sync because all threads are always synchronized in the last iteration of the fixpoint loop.</span></div>
<div class="line"><a id="l00535" name="l00535"></a><span class="lineno">  535</span>    cube.store_gpu-&gt;copy_to(group, *cube.store_cpu);</div>
<div class="line"><a id="l00536" name="l00536"></a><span class="lineno">  536</span>    <span class="keywordflow">if</span>(threadIdx.x == 0) {</div>
<div class="line"><a id="l00537" name="l00537"></a><span class="lineno">  537</span>      cube.fp_iterations += fp_iterations;</div>
<div class="line"><a id="l00538" name="l00538"></a><span class="lineno">  538</span>    }<span class="comment"></span></div>
<div class="line"><a id="l00539" name="l00539"></a><span class="lineno">  539</span><span class="comment">    /** We notify to the CPU that we have propagated the current node. */</span></div>
<div class="line"><a id="l00540" name="l00540"></a><span class="lineno">  540</span>    <span class="keywordflow">if</span>(threadIdx.x == 0) {</div>
<div class="line"><a id="l00541" name="l00541"></a><span class="lineno">  541</span>      cuda::atomic_thread_fence(cuda::memory_order_seq_cst, cuda::thread_scope_system);</div>
<div class="line"><a id="l00542" name="l00542"></a><span class="lineno">  542</span>      cube.ready_to_search.test_and_set(cuda::std::memory_order_seq_cst);</div>
<div class="line"><a id="l00543" name="l00543"></a><span class="lineno">  543</span>      cube.ready_to_search.notify_one();</div>
<div class="line"><a id="l00544" name="l00544"></a><span class="lineno">  544</span>    }</div>
<div class="line"><a id="l00545" name="l00545"></a><span class="lineno">  545</span>  }</div>
<div class="line"><a id="l00546" name="l00546"></a><span class="lineno">  546</span>}</div>
<div class="line"><a id="l00547" name="l00547"></a><span class="lineno">  547</span><span class="comment"></span> </div>
<div class="line"><a id="l00548" name="l00548"></a><span class="lineno">  548</span><span class="comment">/** We update the bound found by the current cube so it is visible to all other cubes.</span></div>
<div class="line"><a id="l00549" name="l00549"></a><span class="lineno">  549</span><span class="comment"> * Note that this operation might not always succeed, which is okay, the best bound is still saved locally in `gpu_cubes` and then reduced at the end (in `reduce_cubes`).</span></div>
<div class="line"><a id="l00550" name="l00550"></a><span class="lineno">  550</span><span class="comment"> * The worst that can happen is that a best bound is found twice, which does not prevent the correctness of the algorithm.</span></div>
<div class="line"><a id="l00551" name="l00551"></a><span class="lineno">  551</span><span class="comment"> *</span></div>
<div class="line"><a id="l00552" name="l00552"></a><span class="lineno">  552</span><span class="comment"> * \return `true` if the best bound has changed. Can return `false` if the best bound was updated by another thread meanwhile.</span></div>
<div class="line"><a id="l00553" name="l00553"></a><span class="lineno">  553</span><span class="comment"> */</span></div>
<div class="line"><a id="l00554" name="l00554"></a><span class="lineno">  554</span><span class="keywordtype">bool</span> update_global_best_bound(CPUData&amp; global, <span class="keywordtype">size_t</span> cube_idx) {</div>
<div class="line"><a id="l00555" name="l00555"></a><span class="lineno">  555</span>  <span class="keyword">const</span> <span class="keyword">auto</span>&amp; cube = global.cpu_cubes[cube_idx].cube;</div>
<div class="line"><a id="l00556" name="l00556"></a><span class="lineno">  556</span>  assert(cube.bab-&gt;is_optimization());</div>
<div class="line"><a id="l00557" name="l00557"></a><span class="lineno">  557</span>  <span class="comment">// We retrieve the best bound found by the current cube.</span></div>
<div class="line"><a id="l00558" name="l00558"></a><span class="lineno">  558</span>  <span class="keyword">auto</span> local_best = cube.bab-&gt;optimum().project(cube.bab-&gt;objective_var());</div>
<div class="line"><a id="l00559" name="l00559"></a><span class="lineno">  559</span>  <span class="comment">// We update the global `best_bound`.</span></div>
<div class="line"><a id="l00560" name="l00560"></a><span class="lineno">  560</span>  <span class="keywordflow">if</span>(cube.bab-&gt;is_maximization()) {</div>
<div class="line"><a id="l00561" name="l00561"></a><span class="lineno">  561</span>    <span class="keywordflow">return</span> global.best_bound.meet_lb(dual&lt;Itv::LB&gt;(local_best.ub()));</div>
<div class="line"><a id="l00562" name="l00562"></a><span class="lineno">  562</span>  }</div>
<div class="line"><a id="l00563" name="l00563"></a><span class="lineno">  563</span>  <span class="keywordflow">else</span> {</div>
<div class="line"><a id="l00564" name="l00564"></a><span class="lineno">  564</span>    <span class="keywordflow">return</span> global.best_bound.meet_ub(dual&lt;Itv::UB&gt;(local_best.lb()));</div>
<div class="line"><a id="l00565" name="l00565"></a><span class="lineno">  565</span>  }</div>
<div class="line"><a id="l00566" name="l00566"></a><span class="lineno">  566</span>}</div>
<div class="line"><a id="l00567" name="l00567"></a><span class="lineno">  567</span><span class="comment"></span> </div>
<div class="line"><a id="l00568" name="l00568"></a><span class="lineno">  568</span><span class="comment">/** This function essentially does the converse operation of `update_global_best_bound`.</span></div>
<div class="line"><a id="l00569" name="l00569"></a><span class="lineno">  569</span><span class="comment"> * We directly update the store with the global best bound.</span></div>
<div class="line"><a id="l00570" name="l00570"></a><span class="lineno">  570</span><span class="comment"> * This function should be called in each node, since the best bound is erased on backtracking (it is not included in the snapshot).</span></div>
<div class="line"><a id="l00571" name="l00571"></a><span class="lineno">  571</span><span class="comment"> */</span></div>
<div class="line"><a id="l00572" name="l00572"></a><span class="lineno">  572</span><span class="keywordtype">void</span> update_local_best_bound(CPUData&amp; global, <span class="keywordtype">size_t</span> cube_idx) {</div>
<div class="line"><a id="l00573" name="l00573"></a><span class="lineno">  573</span>  <span class="keywordflow">if</span>(global.cpu_cubes[cube_idx].cube.bab-&gt;is_optimization()) {</div>
<div class="line"><a id="l00574" name="l00574"></a><span class="lineno">  574</span>    <span class="keyword">auto</span>&amp; cube = global.cpu_cubes[cube_idx].cube;</div>
<div class="line"><a id="l00575" name="l00575"></a><span class="lineno">  575</span>    VarEnv&lt;bt::standard_allocator&gt; empty_env{};</div>
<div class="line"><a id="l00576" name="l00576"></a><span class="lineno">  576</span>    <span class="keyword">auto</span> best_formula = cube.bab-&gt;template deinterpret_best_bound&lt;bt::standard_allocator&gt;(</div>
<div class="line"><a id="l00577" name="l00577"></a><span class="lineno">  577</span>      cube.bab-&gt;is_maximization()</div>
<div class="line"><a id="l00578" name="l00578"></a><span class="lineno">  578</span>      ? <a class="code hl_typedef" href="common__solving_8hpp.html#ab7cbd01c4c671c527f582fffb1125923">Itv</a>(dual&lt;Itv::UB&gt;(global.best_bound.lb()))</div>
<div class="line"><a id="l00579" name="l00579"></a><span class="lineno">  579</span>      : <a class="code hl_typedef" href="common__solving_8hpp.html#ab7cbd01c4c671c527f582fffb1125923">Itv</a>(dual&lt;Itv::LB&gt;(global.best_bound.ub())));</div>
<div class="line"><a id="l00580" name="l00580"></a><span class="lineno">  580</span>    IDiagnostics diagnostics;</div>
<div class="line"><a id="l00581" name="l00581"></a><span class="lineno">  581</span>    <span class="keywordtype">bool</span> r = interpret_and_tell(best_formula, empty_env, *cube.store, diagnostics);</div>
<div class="line"><a id="l00582" name="l00582"></a><span class="lineno">  582</span>    assert(r);</div>
<div class="line"><a id="l00583" name="l00583"></a><span class="lineno">  583</span>  }</div>
<div class="line"><a id="l00584" name="l00584"></a><span class="lineno">  584</span>}</div>
<div class="line"><a id="l00585" name="l00585"></a><span class="lineno">  585</span><span class="comment"></span> </div>
<div class="line"><a id="l00586" name="l00586"></a><span class="lineno">  586</span><span class="comment">/** After solving, we merge all the statistics and best solutions from all cubes together, before printing them. */</span></div>
<div class="line"><a id="l00587" name="l00587"></a><span class="lineno">  587</span><span class="keywordtype">void</span> reduce_cubes(CPUData&amp; global) {</div>
<div class="line"><a id="l00588" name="l00588"></a><span class="lineno">  588</span>  <span class="keywordflow">for</span>(<span class="keywordtype">int</span> i = 0; i &lt; global.cpu_cubes.size(); ++i) {<span class="comment"></span></div>
<div class="line"><a id="l00589" name="l00589"></a><span class="lineno">  589</span><span class="comment">    /** `meet` is the merge operation. */</span></div>
<div class="line"><a id="l00590" name="l00590"></a><span class="lineno">  590</span>    global.root.meet(global.cpu_cubes[i].cube);</div>
<div class="line"><a id="l00591" name="l00591"></a><span class="lineno">  591</span>    global.root.stats.fixpoint_iterations += global.gpu_cubes[i].fp_iterations;</div>
<div class="line"><a id="l00592" name="l00592"></a><span class="lineno">  592</span>  }</div>
<div class="line"><a id="l00593" name="l00593"></a><span class="lineno">  593</span>}</div>
<div class="line"><a id="l00594" name="l00594"></a><span class="lineno">  594</span><span class="comment"></span> </div>
<div class="line"><a id="l00595" name="l00595"></a><span class="lineno">  595</span><span class="comment">/** We configure the GPU according to the user configuration:</span></div>
<div class="line"><a id="l00596" name="l00596"></a><span class="lineno">  596</span><span class="comment"> * 1) Decide the size of the shared memory and return it.</span></div>
<div class="line"><a id="l00597" name="l00597"></a><span class="lineno">  597</span><span class="comment"> * 2) Increase the stack size if needed.</span></div>
<div class="line"><a id="l00598" name="l00598"></a><span class="lineno">  598</span><span class="comment"> * 3) Increase the global memory allocation (we set the limit to around 90% of the global memory).</span></div>
<div class="line"><a id="l00599" name="l00599"></a><span class="lineno">  599</span><span class="comment"> * 4) Guess the &quot;best&quot; number of threads per block and the number of blocks per SM, if not provided.</span></div>
<div class="line"><a id="l00600" name="l00600"></a><span class="lineno">  600</span><span class="comment"> */</span></div>
<div class="line"><a id="l00601" name="l00601"></a><span class="lineno">  601</span><span class="keywordtype">size_t</span> configure_gpu(<a class="code hl_struct" href="struct_abstract_domains.html">CP&lt;Itv&gt;</a>&amp; cp) {</div>
<div class="line"><a id="l00602" name="l00602"></a><span class="lineno">  602</span>  <span class="keyword">auto</span>&amp; config = cp.<a class="code hl_variable" href="struct_abstract_domains.html#a0aa5ac01e4f4a2a8b2811edca6eb8ef9">config</a>;<span class="comment"></span></div>
<div class="line"><a id="l00603" name="l00603"></a><span class="lineno">  603</span><span class="comment">  /** Configure the shared memory size. */</span></div>
<div class="line"><a id="l00604" name="l00604"></a><span class="lineno">  604</span>  <span class="keywordtype">size_t</span> alignment_overhead = 200;</div>
<div class="line"><a id="l00605" name="l00605"></a><span class="lineno">  605</span>  <span class="keywordtype">size_t</span> shared_mem_bytes = DEFAULT_SHARED_MEM_BYTES + alignment_overhead + (cp.<a class="code hl_variable" href="struct_abstract_domains.html#a6163aae266ebdf3370b3fedc63c150a3">store</a>-&gt;vars() * <span class="keyword">sizeof</span>(GPUCube::Itv1));</div>
<div class="line"><a id="l00606" name="l00606"></a><span class="lineno">  606</span>  cudaDeviceProp deviceProp;</div>
<div class="line"><a id="l00607" name="l00607"></a><span class="lineno">  607</span>  cudaGetDeviceProperties(&amp;deviceProp, 0);</div>
<div class="line"><a id="l00608" name="l00608"></a><span class="lineno">  608</span>  <span class="keywordflow">if</span>(shared_mem_bytes &gt;= deviceProp.sharedMemPerBlock || config.only_global_memory) {</div>
<div class="line"><a id="l00609" name="l00609"></a><span class="lineno">  609</span>    shared_mem_bytes = DEFAULT_SHARED_MEM_BYTES;</div>
<div class="line"><a id="l00610" name="l00610"></a><span class="lineno">  610</span>    printf(<span class="stringliteral">&quot;%%%%%%mzn-stat: memory_configuration=\&quot;global\&quot;\n&quot;</span>);</div>
<div class="line"><a id="l00611" name="l00611"></a><span class="lineno">  611</span>  }</div>
<div class="line"><a id="l00612" name="l00612"></a><span class="lineno">  612</span>  <span class="keywordflow">else</span> {</div>
<div class="line"><a id="l00613" name="l00613"></a><span class="lineno">  613</span>    printf(<span class="stringliteral">&quot;%%%%%%mzn-stat: memory_configuration=\&quot;store_shared\&quot;\n&quot;</span>);</div>
<div class="line"><a id="l00614" name="l00614"></a><span class="lineno">  614</span>  }</div>
<div class="line"><a id="l00615" name="l00615"></a><span class="lineno">  615</span>  printf(<span class="stringliteral">&quot;%%%%%%mzn-stat: shared_mem=%&quot;</span> PRIu64 <span class="stringliteral">&quot;\n&quot;</span>, shared_mem_bytes);</div>
<div class="line"><a id="l00616" name="l00616"></a><span class="lineno">  616</span> </div>
<div class="line"><a id="l00617" name="l00617"></a><span class="lineno">  617</span>  <span class="keywordtype">int</span> hint_num_blocks;</div>
<div class="line"><a id="l00618" name="l00618"></a><span class="lineno">  618</span>  <span class="keywordtype">int</span> hint_num_threads;</div>
<div class="line"><a id="l00619" name="l00619"></a><span class="lineno">  619</span>  CUDAE(cudaOccupancyMaxPotentialBlockSize(&amp;hint_num_blocks, &amp;hint_num_threads, (<span class="keywordtype">void</span>*) gpu_propagate, shared_mem_bytes));</div>
<div class="line"><a id="l00620" name="l00620"></a><span class="lineno">  620</span>  <span class="keywordtype">size_t</span> total_global_mem = deviceProp.totalGlobalMem;</div>
<div class="line"><a id="l00621" name="l00621"></a><span class="lineno">  621</span>  <span class="keywordtype">size_t</span> num_sm = deviceProp.multiProcessorCount;</div>
<div class="line"><a id="l00622" name="l00622"></a><span class="lineno">  622</span>  config.and_nodes = (config.and_nodes == 0) ? hint_num_threads : config.and_nodes;</div>
<div class="line"><a id="l00623" name="l00623"></a><span class="lineno">  623</span>  config.or_nodes = (config.or_nodes == 0) ? hint_num_blocks : config.or_nodes;</div>
<div class="line"><a id="l00624" name="l00624"></a><span class="lineno">  624</span>  <span class="comment">// The stack allocated depends on the maximum number of threads per SM, not on the actual number of threads per block.</span></div>
<div class="line"><a id="l00625" name="l00625"></a><span class="lineno">  625</span>  <span class="keywordtype">size_t</span> total_stack_size = num_sm * deviceProp.maxThreadsPerMultiProcessor * config.stack_kb * 1000;</div>
<div class="line"><a id="l00626" name="l00626"></a><span class="lineno">  626</span>  <span class="keywordtype">size_t</span> remaining_global_mem = total_global_mem - total_stack_size;</div>
<div class="line"><a id="l00627" name="l00627"></a><span class="lineno">  627</span>  remaining_global_mem -= remaining_global_mem / 10; <span class="comment">// We leave 10% of global memory free for CUDA allocations, not sure if it is useful though.</span></div>
<div class="line"><a id="l00628" name="l00628"></a><span class="lineno">  628</span>  CUDAEX(cudaDeviceSetLimit(cudaLimitStackSize, config.stack_kb*1000));</div>
<div class="line"><a id="l00629" name="l00629"></a><span class="lineno">  629</span>  CUDAEX(cudaDeviceSetLimit(cudaLimitMallocHeapSize, remaining_global_mem));</div>
<div class="line"><a id="l00630" name="l00630"></a><span class="lineno">  630</span>  <a class="code hl_function" href="statistics_8hpp.html#aa706e08664f7a52ec805a8257bcfb593">print_memory_statistics</a>(<span class="stringliteral">&quot;stack_memory&quot;</span>, total_stack_size);</div>
<div class="line"><a id="l00631" name="l00631"></a><span class="lineno">  631</span>  <a class="code hl_function" href="statistics_8hpp.html#aa706e08664f7a52ec805a8257bcfb593">print_memory_statistics</a>(<span class="stringliteral">&quot;heap_memory&quot;</span>, remaining_global_mem);</div>
<div class="line"><a id="l00632" name="l00632"></a><span class="lineno">  632</span>  printf(<span class="stringliteral">&quot;%% and_nodes=%zu\n&quot;</span>, config.and_nodes);</div>
<div class="line"><a id="l00633" name="l00633"></a><span class="lineno">  633</span>  printf(<span class="stringliteral">&quot;%% or_nodes=%zu\n&quot;</span>, config.or_nodes);</div>
<div class="line"><a id="l00634" name="l00634"></a><span class="lineno">  634</span>  <span class="keywordtype">int</span> num_blocks;</div>
<div class="line"><a id="l00635" name="l00635"></a><span class="lineno">  635</span>  cudaOccupancyMaxActiveBlocksPerMultiprocessor(&amp;num_blocks, (<span class="keywordtype">void</span>*) gpu_propagate, config.and_nodes, shared_mem_bytes);</div>
<div class="line"><a id="l00636" name="l00636"></a><span class="lineno">  636</span>  printf(<span class="stringliteral">&quot;%% max_blocks_per_sm=%d\n&quot;</span>, num_blocks);</div>
<div class="line"><a id="l00637" name="l00637"></a><span class="lineno">  637</span>  <span class="keywordflow">return</span> shared_mem_bytes;</div>
<div class="line"><a id="l00638" name="l00638"></a><span class="lineno">  638</span>}</div>
<div class="line"><a id="l00639" name="l00639"></a><span class="lineno">  639</span> </div>
<div class="line"><a id="l00640" name="l00640"></a><span class="lineno">  640</span><span class="preprocessor">#endif </span><span class="comment">// __CUDACC__</span></div>
<div class="line"><a id="l00641" name="l00641"></a><span class="lineno">  641</span><span class="preprocessor">#endif </span><span class="comment">// TURBO_HYBRID_DIVE_AND_SOLVE_HPP</span></div>
<div class="ttc" id="acommon__solving_8hpp_html"><div class="ttname"><a href="common__solving_8hpp.html">common_solving.hpp</a></div></div>
<div class="ttc" id="acommon__solving_8hpp_html_ab7cbd01c4c671c527f582fffb1125923"><div class="ttname"><a href="common__solving_8hpp.html#ab7cbd01c4c671c527f582fffb1125923">Itv</a></div><div class="ttdeci">Interval&lt; local::ZLB &gt; Itv</div><div class="ttdef"><b>Definition</b> common_solving.hpp:589</div></div>
<div class="ttc" id="acommon__solving_8hpp_html_aceec23d67eb8f6c24010f377a52aee98"><div class="ttname"><a href="common__solving_8hpp.html#aceec23d67eb8f6c24010f377a52aee98">must_quit</a></div><div class="ttdeci">bool must_quit()</div><div class="ttdef"><b>Definition</b> common_solving.hpp:89</div></div>
<div class="ttc" id="acommon__solving_8hpp_html_ad04619f00eb1d7deacc6f2326f0ace5e"><div class="ttname"><a href="common__solving_8hpp.html#ad04619f00eb1d7deacc6f2326f0ace5e">block_signal_ctrlc</a></div><div class="ttdeci">void block_signal_ctrlc()</div><div class="ttdef"><b>Definition</b> common_solving.hpp:77</div></div>
<div class="ttc" id="acommon__solving_8hpp_html_ae74627056bb5f54434f23cc94f5ae732"><div class="ttname"><a href="common__solving_8hpp.html#ae74627056bb5f54434f23cc94f5ae732">check_timeout</a></div><div class="ttdeci">bool check_timeout(A &amp;a, const Timepoint &amp;start)</div><div class="ttdef"><b>Definition</b> common_solving.hpp:101</div></div>
<div class="ttc" id="ahybrid__dive__and__solve_8hpp_html_ab002d8e461e9e10df5c63ee20a3e33a6"><div class="ttname"><a href="hybrid__dive__and__solve_8hpp.html#ab002d8e461e9e10df5c63ee20a3e33a6">hybrid_dive_and_solve</a></div><div class="ttdeci">void hybrid_dive_and_solve(const Configuration&lt; battery::standard_allocator &gt; &amp;config)</div><div class="ttdef"><b>Definition</b> hybrid_dive_and_solve.hpp:237</div></div>
<div class="ttc" id="astatistics_8hpp_html_aa706e08664f7a52ec805a8257bcfb593"><div class="ttname"><a href="statistics_8hpp.html#aa706e08664f7a52ec805a8257bcfb593">print_memory_statistics</a></div><div class="ttdeci">void print_memory_statistics(const char *key, size_t bytes)</div><div class="ttdef"><b>Definition</b> statistics.hpp:12</div></div>
<div class="ttc" id="astruct_abstract_domains_html"><div class="ttname"><a href="struct_abstract_domains.html">AbstractDomains</a></div><div class="ttdef"><b>Definition</b> common_solving.hpp:156</div></div>
<div class="ttc" id="astruct_abstract_domains_html_a0aa5ac01e4f4a2a8b2811edca6eb8ef9"><div class="ttname"><a href="struct_abstract_domains.html#a0aa5ac01e4f4a2a8b2811edca6eb8ef9">AbstractDomains::config</a></div><div class="ttdeci">Configuration&lt; BasicAllocator &gt; config</div><div class="ttdef"><b>Definition</b> common_solving.hpp:283</div></div>
<div class="ttc" id="astruct_abstract_domains_html_a6163aae266ebdf3370b3fedc63c150a3"><div class="ttname"><a href="struct_abstract_domains.html#a6163aae266ebdf3370b3fedc63c150a3">AbstractDomains::store</a></div><div class="ttdeci">abstract_ptr&lt; IStore &gt; store</div><div class="ttdef"><b>Definition</b> common_solving.hpp:268</div></div>
<div class="ttc" id="astruct_abstract_domains_html_a9ab2a88ebb928131d7392df6c2613ddc"><div class="ttname"><a href="struct_abstract_domains.html#a9ab2a88ebb928131d7392df6c2613ddc">AbstractDomains::preprocess</a></div><div class="ttdeci">void preprocess()</div><div class="ttdef"><b>Definition</b> common_solving.hpp:462</div></div>
<div class="ttc" id="astruct_configuration_html"><div class="ttname"><a href="struct_configuration.html">Configuration</a></div><div class="ttdef"><b>Definition</b> config.hpp:29</div></div>
<div class="ttc" id="astruct_configuration_html_a6400dfba9cd09ea3050d18c71c8d47fb"><div class="ttname"><a href="struct_configuration.html#a6400dfba9cd09ea3050d18c71c8d47fb">Configuration::or_nodes</a></div><div class="ttdeci">size_t or_nodes</div><div class="ttdef"><b>Definition</b> config.hpp:41</div></div>
<div class="ttc" id="astruct_unique_light_alloc_html"><div class="ttname"><a href="struct_unique_light_alloc.html">UniqueLightAlloc</a></div><div class="ttdef"><b>Definition</b> common_solving.hpp:136</div></div>
</div><!-- fragment --></div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="dir_d44c64559bbebec7f509842c48db8b23.html">include</a></li><li class="navelem"><a class="el" href="hybrid__dive__and__solve_8hpp.html">hybrid_dive_and_solve.hpp</a></li>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.12.0 </li>
  </ul>
</div>
</body>
</html>
